{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql.types import DateType\n",
    "from pyspark.sql import SQLContext, SparkSession, Window\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.sql.functions import abs, sqrt\n",
    "import pyspark.sql.functions as func\n",
    "\n",
    "#start spark and read raw data\n",
    "sc=pyspark.SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+------+-----+\n",
      "|Time| V1| V2| V3| V4| V5| V6| V7| V8| V9|V10|V11|V12|V13|V14|V15|V16|V17|V18|V19|V20|V21|V22|V23|V24|V25|V26|V27|V28|Amount|Class|\n",
      "+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+------+-----+\n",
      "|   0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|  0|     0|    0|\n",
      "+----+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv('original.csv', header = True)\n",
    "\n",
    "#cast to double\n",
    "df = df.select(*(col(c).cast(\"double\").alias(c) for c in df.columns))\n",
    "\n",
    "#check for null values\n",
    "na = df.select([count(when(isnan(c), c)).alias(c) for c in df.columns])\n",
    "na.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "492"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count fraud\n",
    "\n",
    "df.select(df.Class).where(df.Class == 1.0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284315"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count nonfraud \n",
    "\n",
    "df.select(df.Class).where(df.Class == 0.0).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284807"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count total\n",
    "\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283726"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count distinct\n",
    "\n",
    "df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "473"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count distinct fruad\n",
    "\n",
    "df.select(df.columns).where(df.Class == 1.0).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283253"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count distinct non-fraud\n",
    "\n",
    "df.select(df.columns).where(df.Class == 0.0).distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "283726"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop duplicate\n",
    "df = df.dropDuplicates()\n",
    "df.select(df.Class).count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the data into 80% modeling and 20% out-of-time testing and save as modeling.csv and oot.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.withColumn('team', lit('7'))\n",
    "df = df.withColumn(\"index\", func.row_number().over(Window.partitionBy(\"team\").orderBy(asc(\"Time\"))))\n",
    "df = df.drop('team')\n",
    "modeling_df = df.select('*').where(df.index.between(1, int(283726*0.80)))\n",
    "oot_df = df.select('*').where(df.index.between(int(283726*0.80)+1, 283726))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = modeling_df.select(\"Class\").count()\n",
    "shuffled = modeling_df.rdd.takeSample(False, nrows)\n",
    "modeling_df = sqlContext.createDataFrame(shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeling_df.coalesce(1).write.csv(\"modeling\", header = True)\n",
    "#oot_df.coalesce(1).write.csv(\"oot\", header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the modeling data into 80% base_training and 20% base_testing and save as base_train.csv and base_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeling_df = sqlContext.read.csv('modeling.csv', header = True)\n",
    "modeling_df = modeling_df.select(*(col(c).cast(\"double\").alias(c) for c in modeling_df.columns))\n",
    "\n",
    "\n",
    "#split by row range\n",
    "modeling_df = modeling_df.withColumn('team', lit('7'))\n",
    "modeling_df = modeling_df.withColumn(\"index\", func.row_number().over(Window.partitionBy(\"team\").orderBy('team')))\n",
    "modeling_df = modeling_df.drop('team')\n",
    "nrow = modeling_df.select('Class').count()\n",
    "base_train = modeling_df.select('*').where(modeling_df.index.between(1, int(nrow*0.8)))\n",
    "base_test = modeling_df.select('*').where(modeling_df.index.between(int(nrow*0.8)+1, nrow))\n",
    "print(base_train.select('*').distinct().count())\n",
    "#base_train.coalesce(1).write.csv(\"base_train\", header = True)\n",
    "#base_test.coalesce(1).write.csv(\"base_test\", header = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlContext.clearCache()\n",
    "\n",
    "#normalize columns in modeling.csv and oot.csv\n",
    "oot = sqlContext.read.csv('oot_raw.csv', header = True)\n",
    "oot = oot.select(*(col(c).cast(\"double\").alias(c) for c in oot.columns))\n",
    "base_train = sqlContext.read.csv('base_train_raw.csv', header = True)\n",
    "base_train = oot.select(*(col(c).cast(\"double\").alias(c) for c in base_train.columns))\n",
    "base_test = sqlContext.read.csv('base_test_raw.csv', header = True)\n",
    "base_test = oot.select(*(col(c).cast(\"double\").alias(c) for c in base_test.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max normalization\n",
    "\n",
    "for i in ['Amount', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', \n",
    "            'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', \n",
    "            'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', \n",
    "            'V24', 'V25', 'V26', 'V27', 'V28']:\n",
    "    \n",
    "    minVal = modeling.agg({i: \"min\"}).collect()[0][0]\n",
    "    maxVal = modeling.agg({i: \"max\"}).collect()[0][0]\n",
    "\n",
    "    modeling = modeling.withColumn(i, (modeling[i]-minVal)/(maxVal - minVal))\n",
    "    oot = oot.withColumn(i, (oot[i]-minVal)/(maxVal - minVal))\n",
    "    base_train = base_train.withColumn(i, (base_train[i]-minVal)/(maxVal - minVal))\n",
    "    base_test = base_test.withColumn(i, (base_test[i]-minVal)/(maxVal - minVal))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modeling.coalesce(1).write.csv(\"modeling\", header = True)\n",
    "#oot.coalesce(1).write.csv(\"oot\", header = True)\n",
    "#base_train.coalesce(1).write.csv(\"base_train\", header = True)\n",
    "#base_test.coalesce(1).write.csv(\"base_test\", header = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
