{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM ModelFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries for modeling\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession, Window, Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import pyspark.sql.functions as F\n",
    "import itertools\n",
    "from itertools import repeat\n",
    "import pickle\n",
    "import pyspark\n",
    "import copy\n",
    "\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "\n",
    "#libraries for plotting\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CreateBestModel:\n",
    "    def __init__(self, algo, avgprecision, avgrecall, avgfscore, hyperparams, ootmodel, ootprecision, ootrecall, ootfscore):\n",
    "        self.algo = algo\n",
    "        self.gsPrecision = avgprecision\n",
    "        self.gsFScore = avgfscore\n",
    "        self.gsRecall = avgrecall\n",
    "        self.hyperParams = hyperparams\n",
    "        self.model = ootmodel\n",
    "        self.ootPrecision = ootprecision\n",
    "        self.ootFScore = ootfscore\n",
    "        self.ootRecall = ootrecall\n",
    "\n",
    "#function-based\n",
    "def sample(df, sampling_method, ratio):\n",
    "\n",
    "    notfraud = df.select('*').where(df.Class == 0.0)\n",
    "    fraud = df.select('*').where(df.Class == 1.0)\n",
    "\n",
    "    if sampling_method == \"over\":\n",
    "        nrows = notfraud.select(\"Class\").count()\n",
    "        sample_size = int(nrows*ratio/(1-ratio))\n",
    "        sampled = fraud.rdd.takeSample(True, sample_size, 46)\n",
    "        fraud = sqlContext.createDataFrame(sampled)\n",
    "\n",
    "    elif sampling_method == \"under\":\n",
    "        nrows = fraud.select(\"Class\").count()\n",
    "        sample_size = int(nrows*(1-ratio)/ratio)\n",
    "        sampled = notfraud.rdd.takeSample(False, sample_size, 46)\n",
    "        notfraud = sqlContext.createDataFrame(sampled)\n",
    "    else:\n",
    "        return df\n",
    "    \n",
    "    sampled = fraud.union(notfraud)\n",
    "\n",
    "    #shuffle undersampled dataframe\n",
    "    nrows = sampled.select(\"Class\").count()\n",
    "    shuffled = sampled.rdd.takeSample(False, nrows, 46)\n",
    "    shuffled_df = sqlContext.createDataFrame(shuffled)\n",
    "\n",
    "    return shuffled_df\n",
    "\n",
    "def generateParamGrid(*args):\n",
    "    \n",
    "    grid = list(itertools.product(*args))\n",
    "    return grid\n",
    "\n",
    "def generateClassifier(algo, params, features):\n",
    "\n",
    "    ############################################################################\n",
    "    #TODO: complete this section\n",
    "\n",
    "    def lr(params,features):\n",
    "        print(params)\n",
    "        if len(params) > 2:\n",
    "            lrClassifier = LogisticRegression(featuresCol = 'features',\n",
    "                                          labelCol = 'Class',\n",
    "                                          threshold=params[0],\n",
    "                                           maxIter=params[1],\n",
    "                                           weightCol=params[2])\n",
    "                                          #regParam=params[2])\n",
    "                                          #elasticNetParam=params[2])\n",
    "        else:\n",
    "            lrClassifier = LogisticRegression(featuresCol = 'features',\n",
    "                                          labelCol = 'Class',\n",
    "                                          threshold=params[0],\n",
    "                                           maxIter=params[1])\n",
    "        return lrClassifier\n",
    "\n",
    "\n",
    "    def gbm(params,features):\n",
    "        gbmClassifier = GBTClassifier(featuresCol = 'features',\n",
    "                                      labelCol = 'Class',\n",
    "                                      maxDepth = params[0],\n",
    "                                      minInfoGain = params[1])\n",
    "        return gbmClassifier\n",
    "\n",
    "    def rf(params,features):\n",
    "        rfClassifier = RandomForestClassifier(featuresCol='features',\n",
    "                                              labelCol='Class',\n",
    "                                              maxDepth=params[0],\n",
    "                                              minInfoGain=params[1],\n",
    "                                              numTrees=params[2])\n",
    "\n",
    "        return rfClassifier\n",
    "\n",
    "    def mlp(params,features):\n",
    "        input_layers = len(features)\n",
    "        layers = [input_layers, params[1], 2]\n",
    "        print(layers)\n",
    "        mlpClassifier = MultilayerPerceptronClassifier(featuresCol = 'features',\n",
    "                                                       labelCol = 'Class',\n",
    "                                                       maxIter = params[0],\n",
    "                                                       layers = layers,\n",
    "                                                       stepSize = params[2])\n",
    "        return mlpClassifier\n",
    "\n",
    "    def svm(params, features):\n",
    "        if len(params) > 3:\n",
    "            svmClassifier = LinearSVC(featuresCol = 'features',\n",
    "                         labelCol='Class', \n",
    "                         maxIter=params[0],\n",
    "                         regParam=params[1],\n",
    "                         tol =params[2],\n",
    "                         weightCol=params[3]\n",
    "                         )\n",
    "        \n",
    "        else:\n",
    "            svmClassifier = LinearSVC(featuresCol = 'features',\n",
    "                         labelCol='Class', \n",
    "                         maxIter=params[0],\n",
    "                         regParam=params[1],\n",
    "                         tol =params[2]\n",
    "                         )\n",
    "        \n",
    "        return svmClassifier\n",
    "\n",
    "    def xg(params,features):\n",
    "        return\n",
    "    ############################################################################\n",
    "\n",
    "    getClassifier = {\n",
    "        'lr':lr,\n",
    "        'gbm':gbm,\n",
    "        'rf':rf,\n",
    "        'mlp':mlp,\n",
    "        'svm':svm,\n",
    "        'xg':xg}\n",
    "\n",
    "    return getClassifier[algo](params,features)\n",
    "\n",
    "def crossValidate(df, folds, k, classifier, features, sampling_method, ratio, pool):\n",
    "\n",
    "    def build(fold, df, classifier, features, sampling_method, ratio):\n",
    "\n",
    "        validation = fold\n",
    "        train = df.subtract(fold)\n",
    "\n",
    "#         #add class weight\n",
    "#         notfraud_count = train.select(\"Class\").where(train.Class == 0.0).count()\n",
    "#         total_count = train.select(\"Class\").count()\n",
    "#         balance_ratio = notfraud_count / total_count\n",
    "#         train=train.withColumn(\"classWeights\", F.when(train.Class == 1.0,balance_ratio).otherwise(1-balance_ratio))\n",
    "        \n",
    "        train = sample(train, sampling_method, ratio)\n",
    "        fraud_count = train.select(\"Class\").where(train.Class == 1.0).count()\n",
    "        tot_count = train.select(\"Class\").count()\n",
    "        fraud_ratio = fraud_count / tot_count\n",
    "        print(\"train: \" + str(tot_count))\n",
    "        print(\"fraud ratio: \" + str(fraud_ratio))\n",
    "        \n",
    "        vectorAssembler = VectorAssembler(inputCols = features, outputCol = 'features')\n",
    "        vector_train = vectorAssembler.transform(train)\n",
    "        vector_validate = vectorAssembler.transform(validation)\n",
    "        model = classifier.fit(vector_train)\n",
    "        pred = model.transform(vector_validate)\n",
    "        pos = pred.filter(pred.prediction == 1.0).count()\n",
    "        if pos != 0:\n",
    "            precision = pred.filter(pred.Class == pred.prediction).filter(pred.Class == 1.0).count() / pos\n",
    "        else:\n",
    "            precision = 0\n",
    "        fraud = pred.filter(pred.Class == 1.0).count()\n",
    "        if fraud != 0:\n",
    "            recall = pred.filter(pred.Class == pred.prediction).filter(pred.Class == 1.0).count() / fraud\n",
    "        else:\n",
    "            recall = 0\n",
    "        precision_recall = precision + recall\n",
    "        if precision_recall != 0:\n",
    "            f_score = 2 * precision * recall /(precision_recall)\n",
    "        else:\n",
    "            f_score = 0\n",
    "        #print(\"\\n precision, recall, f_score: \" + str(precision) + \", \" + str(recall) + \", \" + str(f_score))\n",
    "        return [precision, recall, f_score]\n",
    "\n",
    "    #call multiprocessing here\n",
    "    cvperformance = pool.map(lambda fold: build(fold, df, classifier, features, sampling_method, ratio), folds)\n",
    "\n",
    "    #calculate metrics\n",
    "    precision_sum = sum([x[0] for x in cvperformance])\n",
    "    recall_sum = sum([x[1] for x in cvperformance])\n",
    "\n",
    "    avg_precision = precision_sum/k\n",
    "    avg_recall = recall_sum/k\n",
    "    if avg_precision+avg_recall == 0:\n",
    "        avg_fscore = 0\n",
    "    else:\n",
    "        avg_fscore = 2 * avg_precision * avg_recall /(avg_precision+avg_recall)\n",
    "    return [avg_precision,avg_recall,avg_fscore]\n",
    "\n",
    "def gridSearch(df, folds, k, algo, grid, features, sampling_method, ratio, pool):\n",
    "\n",
    "    best_hyper = None\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "    best_fscore = 0\n",
    "\n",
    "    for i in range(len(grid)):\n",
    "        params = list(grid[i])\n",
    "        print(params)\n",
    "        classifier = generateClassifier(algo, params, features)\n",
    "        modelPerformance = crossValidate(df, folds, k, classifier, features, sampling_method, ratio, pool)\n",
    "        print(modelPerformance)\n",
    "        if modelPerformance[2] > best_fscore:\n",
    "            best_hyper = params\n",
    "            best_precision = modelPerformance[0]\n",
    "            best_recall = modelPerformance[1]\n",
    "            best_fscore = modelPerformance[2]\n",
    "\n",
    "    return best_hyper, best_precision, best_recall, best_fscore\n",
    "\n",
    "def ootTest(traindf,testdf, algo,features,params):\n",
    "    vectorAssembler = VectorAssembler(inputCols = features, outputCol = 'features')\n",
    "    classifier = generateClassifier(algo, params, features)\n",
    "    vector_train = vectorAssembler.transform(traindf)\n",
    "    vector_test = vectorAssembler.transform(testdf)\n",
    "    ootmodel = classifier.fit(vector_train)\n",
    "    pred = ootmodel.transform(vector_test)\n",
    "    pos = pred.filter(pred.prediction == 1.0).count()\n",
    "    if pos != 0:\n",
    "        precision = pred.filter(pred.Class == pred.prediction).filter(pred.Class == 1.0).count() / pos\n",
    "    else:\n",
    "        precision = 0\n",
    "    fraud = pred.filter(pred.Class == 1.0).count()\n",
    "    if fraud != 0:\n",
    "        recall = pred.filter(pred.Class == pred.prediction).filter(pred.Class == 1.0).count() / fraud\n",
    "    else:\n",
    "        recall = 0\n",
    "    precision_recall = precision + recall\n",
    "    if precision_recall != 0:\n",
    "        f_score = 2 * precision * recall /(precision_recall)\n",
    "    else:\n",
    "        f_score = 0\n",
    "    print(\"\\n precision, recall, f_score: \" + str(precision) + \", \" + str(recall) + \", \" + str(f_score))\n",
    "    \n",
    "    return ootmodel, precision, recall, f_score\n",
    "\n",
    "def tune(df, k, stratification_flag, sampling_method, ratio, modelobj_flag, features, algo, *args, **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    Entry point of this suite of functions. returns cv metrics or a model object\n",
    "    Example:\n",
    "        >>> cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True,\n",
    "        'None', 0, False, features, 'mlp', [100], [15], [0.03])\n",
    "    :param df: data for modeling purpose\n",
    "    :type df: : pyspark dataframe\n",
    "    :param k: number of folds for cross validation\n",
    "    :type k: int\n",
    "    :param stratification_flag: specifies whether fraud ratio is fixed for each fold. True for stratification\n",
    "    :type stratification_flag: boolean\n",
    "    :param sampling_method: \"over\" for oversampling minority class, \"under\" for undersampling majority class, \"None\"\n",
    "    :type sampling_method: str\n",
    "    :param ratio: targeted fraud ratio after sampling.\n",
    "    :type ratio: float\n",
    "    :param modelobj_flag: specifies whether to return a model object for out of time test. if False, returns cv performancce\n",
    "    :type modelobj_flag: float\n",
    "    :param features: features for training\n",
    "    :type features: list\n",
    "    :param *args: a sequence of params for hyperparams tuning. ex. [values for params1], [values for params2],...\n",
    "    :type *args: list\n",
    "    :returns: model object or cross validation metrics depending on modelobj_flag\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    pool = ThreadPool(3)\n",
    "\n",
    "    #reduce df dimenions to include features and class\n",
    "    cols = features+['Class', 'index']\n",
    "    df = df.select(cols)\n",
    "    df = df.select(*(F.col(c).cast(\"double\").alias(c) for c in df.columns))\n",
    "    df.cache()\n",
    "    #df.drop(\"index\")\n",
    "    \n",
    "    ########################ClassWeights#################################\n",
    "    if algo in [\"lr\", \"svm\"] and [\"ClassWeigts\"] in args:\n",
    "        #add class weight\n",
    "        balance_ratio = args[-1][0]\n",
    "        df=df.withColumn(\"classWeights\", when(df.Class == 1.0,balance_ratio).otherwise(1-balance_ratio))\n",
    "    ########################ClassWeights#################################\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    if stratification_flag == False:\n",
    "        tot_count = df.select(\"Class\").count()\n",
    "        n = int(tot_count / k)\n",
    "\n",
    "        #create sub-dataframe iteratively\n",
    "        fold_start = 1\n",
    "        fold_end = n\n",
    "        for i in range(k):\n",
    "            fold = df.select('*').where(df.index.between(fold_start, fold_end))\n",
    "            folds.append(fold)\n",
    "            fold_start = fold_end + 1\n",
    "            fold_end = fold_start + n\n",
    "            if i == k-2:\n",
    "                end = tot_count\n",
    "                \n",
    "    if stratification_flag == True:\n",
    "        fraud = df.select(\"*\").where(df.Class == 1.0)\n",
    "        #shuffle undersampled dataframe\n",
    "        nrows = fraud.select(\"Class\").count()\n",
    "        shuffled = fraud.rdd.takeSample(False, nrows, 46)\n",
    "        fraud = sqlContext.createDataFrame(shuffled)\n",
    "        #add row index to dataframe\n",
    "        fraud = fraud.withColumn('dummy', F.lit('7'))\n",
    "        fraud = fraud.withColumn(\"temp_index\", F.row_number().over(Window.partitionBy(\"dummy\").orderBy(\"dummy\")))\n",
    "        fraud = fraud.drop('dummy')\n",
    "        fraud_count = fraud.select(\"Class\").count()\n",
    "        each_fraud = int(fraud_count/k)\n",
    "\n",
    "        notfraud = df.select(\"*\").where(df.Class == 0.0)\n",
    "        nrows = notfraud.select(\"Class\").count()\n",
    "        shuffled = notfraud.rdd.takeSample(False, nrows, 46)\n",
    "        notfraud = sqlContext.createDataFrame(shuffled)\n",
    "        #add row index to dataframe\n",
    "        notfraud = notfraud.withColumn('dummy', F.lit('7'))\n",
    "        notfraud = notfraud.withColumn(\"temp_index\", F.row_number().over(Window.partitionBy(\"dummy\").orderBy(\"dummy\")))\n",
    "        notfraud = notfraud.drop('dummy')\n",
    "        notfraud_count = notfraud.select(\"Class\").count()\n",
    "        each_notfraud = int(notfraud_count/k)\n",
    "\n",
    "        fraud_start = 1\n",
    "        fraud_end = each_fraud\n",
    "        notfraud_start = 1\n",
    "        notfraud_end = each_notfraud\n",
    "\n",
    "        for i in range(k):\n",
    "            fraud_fold  = fraud.select('*').where(fraud.temp_index.between(fraud_start, fraud_end))\n",
    "            notfraud_fold = notfraud.select('*').where(notfraud.temp_index.between(notfraud_start, notfraud_end))\n",
    "            fold = fraud_fold.union(notfraud_fold).drop(\"temp_index\")\n",
    "            folds.append(fold)\n",
    "            fraud_start = fraud_end + 1\n",
    "            fraud_end = fraud_start + each_fraud\n",
    "            notfraud_start = notfraud_end + 1\n",
    "            notfraud_end = notfraud_start + each_notfraud\n",
    "            if i == k-2:\n",
    "                fraud_end = fraud_count\n",
    "                notfraud_end = notfraud_count\n",
    "\n",
    "\n",
    "    #generate hyperparam combo\n",
    "    grid = generateParamGrid(*args)\n",
    "\n",
    "    #conduct grid search:\n",
    "    best_hyper, best_precision, best_recall, best_fscore = gridSearch(df, folds, k, algo, grid, features, sampling_method, ratio, pool)\n",
    "\n",
    "    if modelobj_flag == True:\n",
    "        #generate a model obj\n",
    "        traindf = sample(df, sampling_method, ratio)\n",
    "        testdf = sqlContext.read.csv(\"oot.csv\", header = True)\n",
    "        cols = features+['Class', 'index']\n",
    "        testdf = testdf.select(cols)\n",
    "        testdf = testdf.select(*(F.col(c).cast(\"double\").alias(c) for c in testdf.columns))\n",
    "        model, precision, recall, fscore = ootTest(traindf, testdf, algo,features,best_hyper)\n",
    "        \n",
    "        modelobj = CreateBestModel(algo, best_precision, best_recall, best_fscore, best_hyper, \n",
    "                                   model, precision, recall, fscore)\n",
    "        return modelobj\n",
    "\n",
    "    return best_hyper, best_precision, best_recall, best_fscore\n",
    "\n",
    "def save(content, filename):\n",
    "\n",
    "    pickle.dump(content, open(filename, \"wb\"))\n",
    "\n",
    "def load(filename):\n",
    "\n",
    "    content = pickle.load(open(filename, \"rb\"))\n",
    "    return content\n",
    "\n",
    "def generateStratifiedFolds(df,k):\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15g\n"
     ]
    }
   ],
   "source": [
    "sc=pyspark.SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "print(sc._conf.get('spark.executor.memory'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) base model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-14726739.311762368,59246332.48195211,-36144975.021986455,14742480.91466465,-25364288.64520384,-3767015.820038546,-68775306.14284453,66461467.81416764,-15085794.759309432,-61143287.85295966,17078537.307008952,-41176176.00545584,648927.3374664115,-59599664.804977305,88145.48072371438,-33211891.71134393,-87030116.80309927,-13127958.268909656,4976008.615676296,42010881.34638583,55063825.53555207,5338652.615250678,62810405.88959686,87774.72992524393,7209034.371587852,1002599.4896964767,65422281.451696455,55310384.03539758,4433019.159676856]\n",
      "\n",
      "Intercept: 9504.97585709148\n",
      "EVALUATE PREDICTION ON TEST SET\n",
      "+--------------------+-----+--------------------+----------+\n",
      "|            features|Class|       rawPrediction|prediction|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "|[0.975813201,0.76...|  0.0|[2.82879784147619...|       0.0|\n",
      "|[0.947109992,0.77...|  0.0|[2.86692958902018...|       0.0|\n",
      "|[0.975559578,0.76...|  0.0|[2.82363387265087...|       0.0|\n",
      "|[0.935329608,0.78...|  0.0|[2.68070038446407...|       0.0|\n",
      "|[0.986674528,0.76...|  0.0|[2.86357707175962...|       0.0|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[4.5289e+04 1.6000e+01]\n",
      " [1.5000e+01 7.6000e+01]]\n",
      "\n",
      "Overall Evaluation:\n",
      "Accuracy = 0.9993171204511411\n",
      "fMeasure = 0.9993171204511411\n",
      "precision = 0.9993171204511411\n",
      "recall = 0.9993171204511411\n",
      "Area under Precision Recall Curve = 0.7433812188225507\n",
      "Area under ROC = 0.9543385430374338\n",
      "\n",
      "Class 1 Evaluation:\n",
      "fMeasure = 0.8306010928961749\n",
      "false positive rate = 0.0003531619026597506\n",
      "precision = 0.8260869565217391\n",
      "recall = 0.8351648351648352\n",
      "\n",
      "Class 0 Evaluation:\n",
      "fMeasure = 0.9996689034080876\n",
      "false positive rate = 0.16483516483516483\n",
      "precision = 0.9996689034080876\n",
      "recall = 0.9996468380973402\n"
     ]
    }
   ],
   "source": [
    "training = sqlContext.read.csv('base_train.csv', header = True)\n",
    "testing = sqlContext.read.csv('base_test.csv', header = True)\n",
    "\n",
    "training = training.select(*(col(c).cast(\"double\").alias(c) for c in training.columns))\n",
    "testing = testing.select(*(col(c).cast(\"double\").alias(c) for c in testing.columns))\n",
    "\n",
    "# Preparing training and test data for model building\n",
    "vectorAssembler =VectorAssembler(inputCols=['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V23','V24','V25','V26','V27',\n",
    "                                            'V28','Amount'],outputCol='features')\n",
    "\n",
    "training_data = vectorAssembler.transform(training).select('features','Class')\n",
    "testing_data = vectorAssembler.transform(testing).select('features','Class')\n",
    "\n",
    "# Build Model\n",
    "lsvc = LinearSVC(maxIter=100, regParam=0, standardization=True, tol=1e-6, threshold=0, aggregationDepth=2,\n",
    "                 featuresCol = 'features', labelCol='Class')\n",
    "\n",
    "# Fit the model on training data\n",
    "lsvcModel  = lsvc.fit(training_data)\n",
    "# Print the coefficients and intercept for linearsSVC\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"\\nIntercept: \" + str(lsvcModel.intercept))\n",
    "\n",
    "# Compute raw scores on the test set\n",
    "print(\"EVALUATE PREDICTION ON TEST SET\")\n",
    "pred_results = lsvcModel.transform(testing_data)\n",
    "pred_results.show(5)\n",
    "\n",
    "# Convert to RDD and just incliding prediction and class to calculate metrics\n",
    "predictionAndLabels = pred_results.select('Class','prediction').rdd.map(lambda lp: (float(lp.prediction), lp.Class))\n",
    "\n",
    "# To print RDD\n",
    "#print(predictionAndLabels.collect())\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(\"\\nOverall Evaluation:\")\n",
    "print(\"Accuracy = %s\" % metrics.accuracy)\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure())\n",
    "print(\"precision = %s\" % metrics.precision())\n",
    "print(\"recall = %s\" % metrics.recall())\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Class\",metricName=\"areaUnderPR\")\n",
    "print(\"Area under Precision Recall Curve = %s\" % evaluator.evaluate(pred_results))\n",
    "evaluator=  BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Class\",metricName=\"areaUnderROC\")\n",
    "print(\"Area under ROC = %s\" % evaluator.evaluate(pred_results))\n",
    "\n",
    "print(\"\\nClass 1 Evaluation:\")\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure(1.0,1.0))\n",
    "print(\"false positive rate = %s\" % metrics.falsePositiveRate(1.0))\n",
    "print(\"precision = %s\" % metrics.precision(1.0))\n",
    "print(\"recall = %s\" % metrics.recall(1.0))\n",
    "\n",
    "print(\"\\nClass 0 Evaluation:\")\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure(0.0,0.0))\n",
    "print(\"false positive rate = %s\" % metrics.falsePositiveRate(0.0))\n",
    "print(\"precision = %s\" % metrics.precision(0.0))\n",
    "print(\"recall = %s\" % metrics.recall(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) compare random cv vs stratified cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0, 1e-06]\n",
      "train: 152562\n",
      "fraud ratio: 0.0014420366801693738\n",
      "train: 152482\n",
      "fraud ratio: 0.0016592122348867407\n",
      "\n",
      " precision, recall, f_score: 0, 0.0, 0\n",
      "train: 152538\n",
      "fraud ratio: 0.0017372720240202441\n",
      "\n",
      " precision, recall, f_score: 0.868421052631579, 0.6, 0.7096774193548387\n",
      "train: 152553\n",
      "fraud ratio: 0.0018223174896593315\n",
      "\n",
      " precision, recall, f_score: 1.0, 0.46511627906976744, 0.6349206349206349\n",
      "train: 152499\n",
      "fraud ratio: 0.0016655846923586384\n",
      "\n",
      " precision, recall, f_score: 0, 0.0, 0\n",
      "\n",
      " precision, recall, f_score: 1.0, 0.6111111111111112, 0.7586206896551725\n",
      "cv precision: 0.5736842105263158\n",
      "cv recall: 0.3352454780361757\n",
      "cv f-score: 0.42319013190969806\n",
      "cv hyper: [100, 0, 1e-06]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['Amount', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', \n",
    "            'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', \n",
    "            'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', \n",
    "            'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28']\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, False, 'None', 0, False, features, 'svm', [100], [0], [1e-6])\n",
    "print(\"cv precision:\", cv_precision)\n",
    "print(\"cv recall:\", cv_recall)\n",
    "print(\"cv f-score:\", cv_fscore)\n",
    "print(\"cv hyper:\", cv_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stratified cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0, 1e-06]\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "\n",
      " precision, recall, f_score: 0.7647058823529411, 0.21311475409836064, 0.3333333333333333\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "\n",
      " precision, recall, f_score: 0, 0.0, 0\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "\n",
      " precision, recall, f_score: 0.7368421052631579, 0.22580645161290322, 0.345679012345679\n",
      "train: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "\n",
      " precision, recall, f_score: 1.0, 0.016129032258064516, 0.031746031746031744\n",
      "\n",
      " precision, recall, f_score: 0.8064516129032258, 0.4098360655737705, 0.5434782608695652\n",
      "cv precision: 0.6615999201038649\n",
      "cv recall: 0.1729772607086198\n",
      "cv f-score: 0.27425082903224357\n",
      "cv hyper: [100, 0, 1e-06]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['Amount', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', \n",
    "            'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', \n",
    "            'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', \n",
    "            'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28']\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'None', 0, False, features, 'svm', [100], [0], [1e-6])\n",
    "print(\"cv precision:\", cv_precision)\n",
    "print(\"cv recall:\", cv_recall)\n",
    "print(\"cv f-score:\", cv_fscore)\n",
    "print(\"cv hyper:\", cv_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0, 1e-06]\n",
      "train: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.7750688074051374, 0.490058170280275, 0.6004595717232821]\n",
      "[100, 0, 1e-08]\n",
      "train: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.6755409410140868, 0.6402432575356954, 0.6574186453223684]\n",
      "[100, 0.2, 1e-06]\n",
      "train: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.51, 0.0780539397144368, 0.13538727169719694]\n",
      "[100, 0.2, 1e-08]\n",
      "train: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.51, 0.0780539397144368, 0.13538727169719694]\n",
      "[100, 0.4, 1e-06]\n",
      "train: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.2, 0.00967741935483871, 0.018461538461538463]\n",
      "[100, 0.4, 1e-08]\n",
      "train: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.2, 0.00967741935483871, 0.018461538461538463]\n",
      "gs precision: 0.6755409410140868\n",
      "gs recall: 0.6402432575356954\n",
      "gs f-score: 0.6574186453223684\n",
      "gs hyper: [100, 0, 1e-08]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['Amount', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', \n",
    "            'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', \n",
    "            'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', \n",
    "            'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28']\n",
    "#cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'None', 0, False, features, 'svm', [100, 500, 1000], [0, 0.1, 0.5, 0.9], [1e-2,1e-5,1e-8])\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'None', 0, False, features, 'svm', [100], [0,0.2,0.4], [1e-6,1e-8])\n",
    "#cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'None', 0, False, features, 'svm', [100], [0], [1e-6])\n",
    "print(\"gs precision:\", cv_precision)\n",
    "print(\"gs recall:\", cv_recall)\n",
    "print(\"gs f-score:\", cv_fscore)\n",
    "print(\"gs hyper:\", cv_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Use best hpyerparameter from step 3 to fit base_train and test base_test for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-13528744.347947136,54426744.711458735,-33204643.3530871,13543205.318235964,-23300948.457603954,-3460575.5478901234,-63180553.049645424,61054941.14418527,-13858591.252934977,-56169386.349511035,15689227.52030823,-37826564.77438965,596138.2089491233,-54751334.38766589,80974.99669401855,-30510161.335213408,-79950366.20477463,-12060021.40029758,4571218.83077822,38593368.03405892,50584477.53211836,4904362.360018087,57700886.84596754,80634.40583859642,6622591.760905972,921039.736766686,60100290.8002659,50810978.9362336,4072400.636412491]\n",
      "\n",
      "Intercept: 8731.76233517172\n",
      "EVALUATE PREDICTION ON TEST SET\n",
      "+--------------------+-----+--------------------+----------+\n",
      "|            features|Class|       rawPrediction|prediction|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "|[0.975813201,0.76...|  0.0|[2.59868020301221...|       0.0|\n",
      "|[0.947109992,0.77...|  0.0|[2.63370999889267...|       0.0|\n",
      "|[0.975559578,0.76...|  0.0|[2.59393631559972...|       0.0|\n",
      "|[0.935329608,0.78...|  0.0|[2.46263022345509...|       0.0|\n",
      "|[0.986674528,0.76...|  0.0|[2.63063020379513...|       0.0|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[4.5289e+04 1.6000e+01]\n",
      " [1.5000e+01 7.6000e+01]]\n",
      "\n",
      "Overall Evaluation:\n",
      "Accuracy = 0.9993171204511411\n",
      "fMeasure = 0.9993171204511411\n",
      "precision = 0.9993171204511411\n",
      "recall = 0.9993171204511411\n",
      "Area under Precision Recall Curve = 0.7433812188225508\n",
      "Area under ROC = 0.954338543037462\n",
      "\n",
      "Class 1 Evaluation:\n",
      "fMeasure = 0.8306010928961749\n",
      "false positive rate = 0.0003531619026597506\n",
      "precision = 0.8260869565217391\n",
      "recall = 0.8351648351648352\n",
      "\n",
      "Class 0 Evaluation:\n",
      "fMeasure = 0.9996689034080876\n",
      "false positive rate = 0.16483516483516483\n",
      "precision = 0.9996689034080876\n",
      "recall = 0.9996468380973402\n"
     ]
    }
   ],
   "source": [
    "training = sqlContext.read.csv('base_train.csv', header = True)\n",
    "testing = sqlContext.read.csv('base_test.csv', header = True)\n",
    "\n",
    "training = training.select(*(col(c).cast(\"double\").alias(c) for c in training.columns))\n",
    "testing = testing.select(*(col(c).cast(\"double\").alias(c) for c in testing.columns))\n",
    "\n",
    "# Preparing training and test data for model building\n",
    "vectorAssembler =VectorAssembler(inputCols=['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V23','V24','V25','V26','V27',\n",
    "                                            'V28','Amount'],outputCol='features')\n",
    "\n",
    "training_data = vectorAssembler.transform(training).select('features','Class')\n",
    "testing_data = vectorAssembler.transform(testing).select('features','Class')\n",
    "\n",
    "# Build Model\n",
    "lsvc = LinearSVC(maxIter=100, regParam=0, standardization=True, tol=1e-6, threshold=0, aggregationDepth=2,\n",
    "                 featuresCol = 'features', labelCol='Class')\n",
    "\n",
    "# Fit the model on training data\n",
    "lsvcModel  = lsvc.fit(training_data)\n",
    "# Print the coefficients and intercept for linearsSVC\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"\\nIntercept: \" + str(lsvcModel.intercept))\n",
    "\n",
    "# Compute raw scores on the test set\n",
    "print(\"EVALUATE PREDICTION ON TEST SET\")\n",
    "pred_results = lsvcModel.transform(testing_data)\n",
    "pred_results.show(5)\n",
    "\n",
    "# Convert to RDD and just incliding prediction and class to calculate metrics\n",
    "predictionAndLabels = pred_results.select('Class','prediction').rdd.map(lambda lp: (float(lp.prediction), lp.Class))\n",
    "\n",
    "# To print RDD\n",
    "#print(predictionAndLabels.collect())\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(\"\\nOverall Evaluation:\")\n",
    "print(\"Accuracy = %s\" % metrics.accuracy)\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure())\n",
    "print(\"precision = %s\" % metrics.precision())\n",
    "print(\"recall = %s\" % metrics.recall())\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Class\",metricName=\"areaUnderPR\")\n",
    "print(\"Area under Precision Recall Curve = %s\" % evaluator.evaluate(pred_results))\n",
    "evaluator=  BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Class\",metricName=\"areaUnderROC\")\n",
    "print(\"Area under ROC = %s\" % evaluator.evaluate(pred_results))\n",
    "\n",
    "print(\"\\nClass 1 Evaluation:\")\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure(1.0,1.0))\n",
    "print(\"false positive rate = %s\" % metrics.falsePositiveRate(1.0))\n",
    "print(\"precision = %s\" % metrics.precision(1.0))\n",
    "print(\"recall = %s\" % metrics.recall(1.0))\n",
    "\n",
    "print(\"\\nClass 0 Evaluation:\")\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure(0.0,0.0))\n",
    "print(\"false positive rate = %s\" % metrics.falsePositiveRate(0.0))\n",
    "print(\"precision = %s\" % metrics.precision(0.0))\n",
    "print(\"recall = %s\" % metrics.recall(0.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13528744.34794714 54426744.71145874 33204643.3530871  13543205.31823596\n",
      " 23300948.45760395  3460575.54789012 63180553.04964542 61054941.14418527\n",
      " 13858591.25293498 56169386.34951103 15689227.52030823 37826564.77438965\n",
      "   596138.20894912 54751334.38766589    80974.99669402 30510161.33521341\n",
      " 79950366.20477463 12060021.40029758  4571218.83077822 38593368.03405892\n",
      " 50584477.53211836  4904362.36001809 57700886.84596754    80634.4058386\n",
      "  6622591.76090597   921039.73676669 60100290.8002659  50810978.9362336\n",
      "  4072400.63641249]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = ['Amount', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28']\n",
    "featureImportance = np.abs(lsvcModel.coefficients)\n",
    "print(featureImportance)\n",
    "tmp = pd.DataFrame({'Feature': features, 'Feature importance': featureImportance})\n",
    "tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
    "plt.figure(figsize = (15,8))\n",
    "plt.title('Features importance',fontsize=14)\n",
    "s = sns.barplot(x='Feature',y='Feature importance',data=tmp)\n",
    "s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Build model with important features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing V23"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.05099865423787985,0.002003862235226928,-0.07053299340152917,0.36662655392739657,-0.10971957875384993,-0.05026650958168456,-0.1963272297449319,2.5013084938835877,-0.5453974309462307,-0.667497855756912,0.6590998173466558,-1.2714398137418057,-0.002511002479939006,-1.4646152190407913,-0.016002927192606188,-1.2432394971419478,-1.1917037625095137,-0.036804366456508794,0.0015370027749541735,0.002158590659681067,1.8116398343039055,-0.026520706075086775,-0.0020944072273670496,-0.029856932274003194,0.00015911545481921564,-0.1270264487030034,-0.09835248868238969,-0.0757163556349462]\n",
      "\n",
      "Intercept: -4.618736584460154e-05\n",
      "EVALUATE PREDICTION ON TEST SET\n",
      "+--------------------+-----+--------------------+----------+\n",
      "|            features|Class|       rawPrediction|prediction|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "|[0.975813201,0.76...|  0.0|[1.20943260377264...|       0.0|\n",
      "|[0.947109992,0.77...|  0.0|[1.18241062331554...|       0.0|\n",
      "|[0.975559578,0.76...|  0.0|[1.16517664705076...|       0.0|\n",
      "|[0.935329608,0.78...|  0.0|[1.22983945445401...|       0.0|\n",
      "|[0.986674528,0.76...|  0.0|[1.22055367054349...|       0.0|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[4.5295e+04 1.0000e+01]\n",
      " [4.3000e+01 4.8000e+01]]\n",
      "\n",
      "Overall Evaluation:\n",
      "Accuracy = 0.9988324962551767\n",
      "fMeasure = 0.9988324962551767\n",
      "precision = 0.9988324962551767\n",
      "recall = 0.9988324962551767\n",
      "Area under Precision Recall Curve = 0.7739035381326781\n",
      "Area under ROC = 0.977537350630888\n",
      "\n",
      "Class 1 Evaluation:\n",
      "fMeasure = 0.6442953020134228\n",
      "false positive rate = 0.0002207261891623441\n",
      "precision = 0.8275862068965517\n",
      "recall = 0.5274725274725275\n",
      "\n",
      "Class 0 Evaluation:\n",
      "fMeasure = 0.9990515682209185\n",
      "false positive rate = 0.4725274725274725\n",
      "precision = 0.9990515682209185\n",
      "recall = 0.9997792738108376\n"
     ]
    }
   ],
   "source": [
    "training = sqlContext.read.csv('base_train.csv', header = True)\n",
    "testing = sqlContext.read.csv('base_test.csv', header = True)\n",
    "\n",
    "training = training.select(*(col(c).cast(\"double\").alias(c) for c in training.columns))\n",
    "testing = testing.select(*(col(c).cast(\"double\").alias(c) for c in testing.columns))\n",
    "\n",
    "# Preparing training and test data for model building\n",
    "vectorAssembler =VectorAssembler(inputCols=['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V24','V25','V26','V27',\n",
    "                                            'V28','Amount'],outputCol='features')\n",
    "\n",
    "training_data = vectorAssembler.transform(training).select('features','Class')\n",
    "testing_data = vectorAssembler.transform(testing).select('features','Class')\n",
    "\n",
    "# Build Model\n",
    "lsvc = LinearSVC(maxIter=100, regParam=0, standardization=True, tol=1e-6, threshold=0, aggregationDepth=2,\n",
    "                 featuresCol = 'features', labelCol='Class')\n",
    "\n",
    "# Fit the model on training data\n",
    "lsvcModel  = lsvc.fit(training_data)\n",
    "# Print the coefficients and intercept for linearsSVC\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"\\nIntercept: \" + str(lsvcModel.intercept))\n",
    "\n",
    "# Compute raw scores on the test set\n",
    "print(\"EVALUATE PREDICTION ON TEST SET\")\n",
    "pred_results = lsvcModel.transform(testing_data)\n",
    "pred_results.show(5)\n",
    "\n",
    "# Convert to RDD and just incliding prediction and class to calculate metrics\n",
    "predictionAndLabels = pred_results.select('Class','prediction').rdd.map(lambda lp: (float(lp.prediction), lp.Class))\n",
    "\n",
    "# To print RDD\n",
    "#print(predictionAndLabels.collect())\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(\"\\nOverall Evaluation:\")\n",
    "print(\"Accuracy = %s\" % metrics.accuracy)\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure())\n",
    "print(\"precision = %s\" % metrics.precision())\n",
    "print(\"recall = %s\" % metrics.recall())\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Class\",metricName=\"areaUnderPR\")\n",
    "print(\"Area under Precision Recall Curve = %s\" % evaluator.evaluate(pred_results))\n",
    "evaluator=  BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Class\",metricName=\"areaUnderROC\")\n",
    "print(\"Area under ROC = %s\" % evaluator.evaluate(pred_results))\n",
    "\n",
    "print(\"\\nClass 1 Evaluation:\")\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure(1.0,1.0))\n",
    "print(\"false positive rate = %s\" % metrics.falsePositiveRate(1.0))\n",
    "print(\"precision = %s\" % metrics.precision(1.0))\n",
    "print(\"recall = %s\" % metrics.recall(1.0))\n",
    "\n",
    "print(\"\\nClass 0 Evaluation:\")\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure(0.0,0.0))\n",
    "print(\"false positive rate = %s\" % metrics.falsePositiveRate(0.0))\n",
    "print(\"precision = %s\" % metrics.precision(0.0))\n",
    "print(\"recall = %s\" % metrics.recall(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing v23 and v14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-26189280.614019055,41496728.03850582,-65625510.90336873,10156116.688992428,-44942573.88577605,-6256583.136698389,-123883552.0200343,47167431.39297619,-27360879.893494017,-111102592.72928017,11765922.604073223,-75034500.46012247,463529.88029086345,76787.69099621683,-60480462.29713582,-158397131.14935547,-23877415.891390823,3462738.523693147,29824683.712088402,39088194.28785363,3810934.222223596,76244.69190480285,5170661.250975474,709580.6723290663,46506567.25512824,39576662.32110057,3056423.300732567]\n",
      "\n",
      "Intercept: 6835.458253570818\n",
      "EVALUATE PREDICTION ON TEST SET\n",
      "+--------------------+-----+--------------------+----------+\n",
      "|            features|Class|       rawPrediction|prediction|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "|[0.975813201,0.76...|  0.0|[3.06777306870819...|       0.0|\n",
      "|[0.947109992,0.77...|  0.0|[3.07602216086396...|       0.0|\n",
      "|[0.975559578,0.76...|  0.0|[3.06478413433465...|       0.0|\n",
      "|[0.935329608,0.78...|  0.0|[3.01742181303230...|       0.0|\n",
      "|[0.986674528,0.76...|  0.0|[3.02570971888455...|       0.0|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[45305.     0.]\n",
      " [   91.     0.]]\n",
      "\n",
      "Overall Evaluation:\n",
      "Accuracy = 0.9979954180985109\n",
      "fMeasure = 0.9979954180985109\n",
      "precision = 0.9979954180985109\n",
      "recall = 0.9979954180985109\n",
      "Area under Precision Recall Curve = 0.7287788033132592\n",
      "Area under ROC = 0.8626828419346677\n",
      "\n",
      "Class 1 Evaluation:\n",
      "fMeasure = 0.0\n",
      "false positive rate = 0.0\n",
      "precision = 0.0\n",
      "recall = 0.0\n",
      "\n",
      "Class 0 Evaluation:\n",
      "fMeasure = 0.9979954180985109\n",
      "false positive rate = 1.0\n",
      "precision = 0.9979954180985109\n",
      "recall = 1.0\n"
     ]
    }
   ],
   "source": [
    "training = sqlContext.read.csv('base_train.csv', header = True)\n",
    "testing = sqlContext.read.csv('base_test.csv', header = True)\n",
    "\n",
    "training = training.select(*(col(c).cast(\"double\").alias(c) for c in training.columns))\n",
    "testing = testing.select(*(col(c).cast(\"double\").alias(c) for c in testing.columns))\n",
    "\n",
    "# Preparing training and test data for model building\n",
    "vectorAssembler =VectorAssembler(inputCols=['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22', 'V24','V25','V26','V27',\n",
    "                                            'V28','Amount'],outputCol='features')\n",
    "\n",
    "training_data = vectorAssembler.transform(training).select('features','Class')\n",
    "testing_data = vectorAssembler.transform(testing).select('features','Class')\n",
    "\n",
    "# Build Model\n",
    "lsvc = LinearSVC(maxIter=100, regParam=0, standardization=True, tol=1e-6, threshold=0, aggregationDepth=2,\n",
    "                 featuresCol = 'features', labelCol='Class')\n",
    "\n",
    "# Fit the model on training data\n",
    "lsvcModel  = lsvc.fit(training_data)\n",
    "# Print the coefficients and intercept for linearsSVC\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"\\nIntercept: \" + str(lsvcModel.intercept))\n",
    "\n",
    "# Compute raw scores on the test set\n",
    "print(\"EVALUATE PREDICTION ON TEST SET\")\n",
    "pred_results = lsvcModel.transform(testing_data)\n",
    "pred_results.show(5)\n",
    "\n",
    "# Convert to RDD and just incliding prediction and class to calculate metrics\n",
    "predictionAndLabels = pred_results.select('Class','prediction').rdd.map(lambda lp: (float(lp.prediction), lp.Class))\n",
    "\n",
    "# To print RDD\n",
    "#print(predictionAndLabels.collect())\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(\"\\nOverall Evaluation:\")\n",
    "print(\"Accuracy = %s\" % metrics.accuracy)\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure())\n",
    "print(\"precision = %s\" % metrics.precision())\n",
    "print(\"recall = %s\" % metrics.recall())\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Class\",metricName=\"areaUnderPR\")\n",
    "print(\"Area under Precision Recall Curve = %s\" % evaluator.evaluate(pred_results))\n",
    "evaluator=  BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Class\",metricName=\"areaUnderROC\")\n",
    "print(\"Area under ROC = %s\" % evaluator.evaluate(pred_results))\n",
    "\n",
    "print(\"\\nClass 1 Evaluation:\")\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure(1.0,1.0))\n",
    "print(\"false positive rate = %s\" % metrics.falsePositiveRate(1.0))\n",
    "print(\"precision = %s\" % metrics.precision(1.0))\n",
    "print(\"recall = %s\" % metrics.recall(1.0))\n",
    "\n",
    "print(\"\\nClass 0 Evaluation:\")\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure(0.0,0.0))\n",
    "print(\"false positive rate = %s\" % metrics.falsePositiveRate(0.0))\n",
    "print(\"precision = %s\" % metrics.precision(0.0))\n",
    "print(\"recall = %s\" % metrics.recall(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "removing V25 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.3147691627105632,0.7245572117202671,0.006054552953975236,0.5616744309156111,0.0077907335308473585,-0.009030793781771887,-0.27335233372394224,0.7190123574838607,-1.0595889538827812,-1.059494649522429,1.287603129675375,-1.6680344786885717,-3.369462256117768e-05,-1.390640173768389,-0.0914953558778872,-1.6753328040358186,-1.8922634183994482,-0.07932891227798738,0.04280684498646152,0.40214983893047157,0.9188931353001322,0.0377567699673414,1.7389733276526342,0.0004751647049320766,0.16782217089434998,0.6006479631245139,0.5133492578879651,-0.5199676037163374]\n",
      "\n",
      "Intercept: 8.552045004515997e-05\n",
      "EVALUATE PREDICTION ON TEST SET\n",
      "+--------------------+-----+--------------------+----------+\n",
      "|            features|Class|       rawPrediction|prediction|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "|[0.975813201,0.76...|  0.0|[1.32563603121761...|       0.0|\n",
      "|[0.947109992,0.77...|  0.0|[1.28402734336647...|       0.0|\n",
      "|[0.975559578,0.76...|  0.0|[1.22242515566000...|       0.0|\n",
      "|[0.935329608,0.78...|  0.0|[1.32281376321447...|       0.0|\n",
      "|[0.986674528,0.76...|  0.0|[1.35009006757055...|       0.0|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[4.5292e+04 1.3000e+01]\n",
      " [2.7000e+01 6.4000e+01]]\n",
      "\n",
      "Overall Evaluation:\n",
      "Accuracy = 0.9991188650982465\n",
      "fMeasure = 0.9991188650982465\n",
      "precision = 0.9991188650982465\n",
      "recall = 0.9991188650982465\n",
      "Area under Precision Recall Curve = 0.7686947608258514\n",
      "Area under ROC = 0.9763393653031301\n",
      "\n",
      "Class 1 Evaluation:\n",
      "fMeasure = 0.761904761904762\n",
      "false positive rate = 0.00028694404591104734\n",
      "precision = 0.8311688311688312\n",
      "recall = 0.7032967032967034\n",
      "\n",
      "Class 0 Evaluation:\n",
      "fMeasure = 0.9994042233941614\n",
      "false positive rate = 0.2967032967032967\n",
      "precision = 0.9994042233941614\n",
      "recall = 0.999713055954089\n"
     ]
    }
   ],
   "source": [
    "training = sqlContext.read.csv('base_train.csv', header = True)\n",
    "testing = sqlContext.read.csv('base_test.csv', header = True)\n",
    "\n",
    "training = training.select(*(col(c).cast(\"double\").alias(c) for c in training.columns))\n",
    "testing = testing.select(*(col(c).cast(\"double\").alias(c) for c in testing.columns))\n",
    "\n",
    "# Preparing training and test data for model building\n",
    "vectorAssembler =VectorAssembler(inputCols=['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V23','V24','V26','V27',\n",
    "                                            'V28','Amount'],outputCol='features')\n",
    "\n",
    "training_data = vectorAssembler.transform(training).select('features','Class')\n",
    "testing_data = vectorAssembler.transform(testing).select('features','Class')\n",
    "\n",
    "# Build Model\n",
    "lsvc = LinearSVC(maxIter=100, regParam=0, standardization=True, tol=1e-6, threshold=0, aggregationDepth=2,\n",
    "                 featuresCol = 'features', labelCol='Class')\n",
    "\n",
    "# Fit the model on training data\n",
    "lsvcModel  = lsvc.fit(training_data)\n",
    "# Print the coefficients and intercept for linearsSVC\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"\\nIntercept: \" + str(lsvcModel.intercept))\n",
    "\n",
    "# Compute raw scores on the test set\n",
    "print(\"EVALUATE PREDICTION ON TEST SET\")\n",
    "pred_results = lsvcModel.transform(testing_data)\n",
    "pred_results.show(5)\n",
    "\n",
    "# Convert to RDD and just incliding prediction and class to calculate metrics\n",
    "predictionAndLabels = pred_results.select('Class','prediction').rdd.map(lambda lp: (float(lp.prediction), lp.Class))\n",
    "\n",
    "# To print RDD\n",
    "#print(predictionAndLabels.collect())\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(\"\\nOverall Evaluation:\")\n",
    "print(\"Accuracy = %s\" % metrics.accuracy)\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure())\n",
    "print(\"precision = %s\" % metrics.precision())\n",
    "print(\"recall = %s\" % metrics.recall())\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Class\",metricName=\"areaUnderPR\")\n",
    "print(\"Area under Precision Recall Curve = %s\" % evaluator.evaluate(pred_results))\n",
    "evaluator=  BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Class\",metricName=\"areaUnderROC\")\n",
    "print(\"Area under ROC = %s\" % evaluator.evaluate(pred_results))\n",
    "\n",
    "print(\"\\nClass 1 Evaluation:\")\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure(1.0,1.0))\n",
    "print(\"false positive rate = %s\" % metrics.falsePositiveRate(1.0))\n",
    "print(\"precision = %s\" % metrics.precision(1.0))\n",
    "print(\"recall = %s\" % metrics.recall(1.0))\n",
    "\n",
    "print(\"\\nClass 0 Evaluation:\")\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure(0.0,0.0))\n",
    "print(\"false positive rate = %s\" % metrics.falsePositiveRate(0.0))\n",
    "print(\"precision = %s\" % metrics.precision(0.0))\n",
    "print(\"recall = %s\" % metrics.recall(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) once important features are finalized, stratified cv grid search for marginal improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not removing any features as performance drops with every feature removal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Use stratified cv to compare no sampling, undersampling, and oversampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UnderSampling ratio =  0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0, 1e-06]\n",
      "train: 24600\n",
      "fraud ratio: 0.01\n",
      "train: 24700\n",
      "fraud ratio: 0.01\n",
      "train: 24600\n",
      "fraud ratio: 0.01\n",
      "train: 24600\n",
      "fraud ratio: 0.01\n",
      "train: 24700\n",
      "fraud ratio: 0.01\n",
      "[0.5192261501411168, 0.8347964040190377, 0.6402376706040966]\n",
      "gs precision: 0.5192261501411168\n",
      "gs recall: 0.8347964040190377\n",
      "gs f-score: 0.6402376706040966\n",
      "gs hyper: [100, 0, 1e-06]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V23','V24','V25','V26','V27',\n",
    "                                            'V28','Amount']\n",
    "\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'under', 0.01, False, features, 'svm', [100], [0], [1e-6])\n",
    "\n",
    "print(\"gs precision:\", cv_precision)\n",
    "print(\"gs recall:\", cv_recall)\n",
    "print(\"gs f-score:\", cv_fscore)\n",
    "print(\"gs hyper:\", cv_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UnderSampling ratio = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0, 1e-06]\n",
      "train: 4919\n",
      "fraud ratio: 0.05001016466761537\n",
      "train: 4919\n",
      "fraud ratio: 0.05001016466761537\n",
      "train: 4939\n",
      "fraud ratio: 0.05001012350678275\n",
      "train: 4919\n",
      "fraud ratio: 0.05001016466761537\n",
      "train: 4939\n",
      "fraud ratio: 0.05001012350678275\n",
      "[0.621932988335937, 0.686991010047594, 0.6528451955445479]\n",
      "gs precision: 0.621932988335937\n",
      "gs recall: 0.686991010047594\n",
      "gs f-score: 0.6528451955445479\n",
      "gs hyper: [100, 0, 1e-06]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V23','V24','V25','V26','V27',\n",
    "                                            'V28','Amount']\n",
    "\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'under', 0.05, False, features, 'svm', [100], [0], [1e-6])\n",
    "\n",
    "print(\"gs precision:\", cv_precision)\n",
    "print(\"gs recall:\", cv_recall)\n",
    "print(\"gs f-score:\", cv_fscore)\n",
    "print(\"gs hyper:\", cv_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UnderSampling ratio = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0, 1e-06]\n",
      "train: 2460\n",
      "fraud ratio: 0.1\n",
      "train: 2460\n",
      "fraud ratio: 0.1\n",
      "train: 2460\n",
      "fraud ratio: 0.1\n",
      "train: 2470\n",
      "fraud ratio: 0.1\n",
      "train: 2470\n",
      "fraud ratio: 0.1\n",
      "train: 2460\n",
      "fraud ratio: 0.1\n",
      "train: 2470\n",
      "fraud ratio: 0.1\n",
      "[0.6732960323369854, 0.7340031729243787, 0.7023402304287654]\n",
      "gs precision: 0.6732960323369854\n",
      "gs recall: 0.7340031729243787\n",
      "gs f-score: 0.7023402304287654\n",
      "gs hyper: [100, 0, 1e-06]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V23','V24','V25','V26','V27',\n",
    "                                            'V28','Amount']\n",
    "\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'under', 0.10, False, features, 'svm', [100], [0], [1e-6])\n",
    "\n",
    "print(\"gs precision:\", cv_precision)\n",
    "print(\"gs recall:\", cv_recall)\n",
    "print(\"gs f-score:\", cv_fscore)\n",
    "print(\"gs hyper:\", cv_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UnderSampling ratio = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0, 1e-06]\n",
      "train: 1235\n",
      "fraud ratio: 0.2\n",
      "train: 1230\n",
      "fraud ratio: 0.2\n",
      "train: 1230\n",
      "fraud ratio: 0.2\n",
      "train: 1230\n",
      "fraud ratio: 0.2\n",
      "train: 1235\n",
      "fraud ratio: 0.2\n",
      "[0.6662677082777867, 0.7206240084611316, 0.6923806680110621]\n",
      "gs precision: 0.6662677082777867\n",
      "gs recall: 0.7206240084611316\n",
      "gs f-score: 0.6923806680110621\n",
      "gs hyper: [100, 0, 1e-06]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V23','V24','V25','V26','V27',\n",
    "                                            'V28','Amount']\n",
    "\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'under', 0.20, False, features, 'svm', [100], [0], [1e-6])\n",
    "\n",
    "print(\"gs precision:\", cv_precision)\n",
    "print(\"gs recall:\", cv_recall)\n",
    "print(\"gs f-score:\", cv_fscore)\n",
    "print(\"gs hyper:\", cv_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UnderSampling ratio = 0.40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0, 1e-06]\n",
      "train: 617\n",
      "fraud ratio: 0.40032414910858993\n",
      "train: 614\n",
      "fraud ratio: 0.4006514657980456\n",
      "train: 614\n",
      "fraud ratio: 0.4006514657980456\n",
      "train: 614\n",
      "fraud ratio: 0.4006514657980456\n",
      "train: 617\n",
      "fraud ratio: 0.40032414910858993\n",
      "[0.04531282915525595, 0.344632469592808, 0.08009468131119703]\n",
      "gs precision: 0.04531282915525595\n",
      "gs recall: 0.344632469592808\n",
      "gs f-score: 0.08009468131119703\n",
      "gs hyper: [100, 0, 1e-06]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V23','V24','V25','V26','V27',\n",
    "                                            'V28','Amount']\n",
    "\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'under', 0.40, False, features, 'svm', [100], [0], [1e-6])\n",
    "\n",
    "print(\"gs precision:\", cv_precision)\n",
    "print(\"gs recall:\", cv_recall)\n",
    "print(\"gs f-score:\", cv_fscore)\n",
    "print(\"gs hyper:\", cv_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UnderSampling ratio = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0, 1e-06]\n",
      "train: 494\n",
      "fraud ratio: 0.5\n",
      "train: 492\n",
      "fraud ratio: 0.5\n",
      "train: 492\n",
      "fraud ratio: 0.5\n",
      "train: 492\n",
      "fraud ratio: 0.5\n",
      "train: 494\n",
      "fraud ratio: 0.5\n",
      "[0.12790657414053147, 0.8573241671073506, 0.22260246772993486]\n",
      "gs precision: 0.12790657414053147\n",
      "gs recall: 0.8573241671073506\n",
      "gs f-score: 0.22260246772993486\n",
      "gs hyper: [100, 0, 1e-06]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V23','V24','V25','V26','V27',\n",
    "                                            'V28','Amount']\n",
    "\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'under', 0.50, False, features, 'svm', [100], [0], [1e-6])\n",
    "\n",
    "print(\"gs precision:\", cv_precision)\n",
    "print(\"gs recall:\", cv_recall)\n",
    "print(\"gs f-score:\", cv_fscore)\n",
    "print(\"gs hyper:\", cv_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverSampling ratio = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0, 1e-06]\n",
      "train: 146485\n",
      "fraud ratio: 0.009994197358091272\n",
      "train: 146484\n",
      "fraud ratio: 0.009994265585319899\n",
      "train: 146484\n",
      "fraud ratio: 0.009994265585319899\n",
      "train: 146484\n",
      "fraud ratio: 0.009994265585319899\n",
      "train: 146487\n",
      "fraud ratio: 0.009994060906428556\n",
      "[0.16802689222644868, 0.9475409836065574, 0.2854373457351784]\n",
      "gs precision: 0.16802689222644868\n",
      "gs recall: 0.9475409836065574\n",
      "gs f-score: 0.2854373457351784\n",
      "gs hyper: [100, 0, 1e-06]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V23','V24','V25','V26','V27',\n",
    "                                            'V28','Amount']\n",
    "\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'over', 0.01, False, features, 'svm', [100], [0], [1e-6])\n",
    "\n",
    "print(\"gs precision:\", cv_precision)\n",
    "print(\"gs recall:\", cv_recall)\n",
    "print(\"gs f-score:\", cv_fscore)\n",
    "print(\"gs hyper:\", cv_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverSampling ratio = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0, 1e-06]\n",
      "train: 152653\n",
      "fraud ratio: 0.04999574197690186\n",
      "train: 152652\n",
      "fraud ratio: 0.04999606949139219\n",
      "train: 152652\n",
      "fraud ratio: 0.04999606949139219\n",
      "train: 152652\n",
      "fraud ratio: 0.04999606949139219\n",
      "train: 152655\n",
      "fraud ratio: 0.049995086960793945\n",
      "[0.5469106172103838, 0.6539397144368059, 0.5956555341087958]\n",
      "gs precision: 0.5469106172103838\n",
      "gs recall: 0.6539397144368059\n",
      "gs f-score: 0.5956555341087958\n",
      "gs hyper: [100, 0, 1e-06]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V23','V24','V25','V26','V27',\n",
    "                                            'V28','Amount']\n",
    "\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'over', 0.05, False, features, 'svm', [100], [0], [1e-6])\n",
    "\n",
    "print(\"gs precision:\", cv_precision)\n",
    "print(\"gs recall:\", cv_recall)\n",
    "print(\"gs f-score:\", cv_fscore)\n",
    "print(\"gs hyper:\", cv_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverSampling ratio = 0.10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0, 1e-06]\n",
      "train: 161133\n",
      "fraud ratio: 0.09999813818398466\n",
      "train: 161133\n",
      "fraud ratio: 0.09999813818398466\n",
      "train: 161134\n",
      "fraud ratio: 0.09999751759405215\n",
      "train: 161133\n",
      "fraud ratio: 0.09999813818398466\n",
      "train: 161136\n",
      "fraud ratio: 0.09999627643729521\n",
      "[0.3408762161363902, 0.6438921205711263, 0.4457647580224978]\n",
      "gs precision: 0.3408762161363902\n",
      "gs recall: 0.6438921205711263\n",
      "gs f-score: 0.4457647580224978\n",
      "gs hyper: [100, 0, 1e-06]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V23','V24','V25','V26','V27',\n",
    "                                            'V28','Amount']\n",
    "\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'over', 0.10, False, features, 'svm', [100], [0], [1e-6])\n",
    "\n",
    "print(\"gs precision:\", cv_precision)\n",
    "print(\"gs recall:\", cv_recall)\n",
    "print(\"gs f-score:\", cv_fscore)\n",
    "print(\"gs hyper:\", cv_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverSampling ratio = 0.20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0, 1e-06]\n",
      "train: 181276\n",
      "fraud ratio: 0.1999988967099892\n",
      "train: 181275\n",
      "fraud ratio: 0.2\n",
      "train: 181275\n",
      "fraud ratio: 0.2\n",
      "train: 181275\n",
      "fraud ratio: 0.2\n",
      "train: 181278\n",
      "fraud ratio: 0.19999669016648464\n",
      "[0.5510785611216757, 0.7463775780010576, 0.6340294200872341]\n",
      "gs precision: 0.5510785611216757\n",
      "gs recall: 0.7463775780010576\n",
      "gs f-score: 0.6340294200872341\n",
      "gs hyper: [100, 0, 1e-06]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V23','V24','V25','V26','V27',\n",
    "                                            'V28','Amount']\n",
    "\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'over', 0.20, False, features, 'svm', [100], [0], [1e-6])\n",
    "\n",
    "print(\"gs precision:\", cv_precision)\n",
    "print(\"gs recall:\", cv_recall)\n",
    "print(\"gs f-score:\", cv_fscore)\n",
    "print(\"gs hyper:\", cv_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverSampling ratio = 0.40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0, 1e-06]\n",
      "train: 241700\n",
      "fraud ratio: 0.4\n",
      "train: 241700\n",
      "fraud ratio: 0.4\n",
      "train: 241701\n",
      "fraud ratio: 0.39999834506270143\n",
      "train: 241700\n",
      "fraud ratio: 0.4\n",
      "train: 241705\n",
      "fraud ratio: 0.4\n",
      "[0.04190767734228627, 0.5222104706504495, 0.07758881002730762]\n",
      "gs precision: 0.04190767734228627\n",
      "gs recall: 0.5222104706504495\n",
      "gs f-score: 0.07758881002730762\n",
      "gs hyper: [100, 0, 1e-06]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V23','V24','V25','V26','V27',\n",
    "                                            'V28','Amount']\n",
    "\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'over', 0.40, False, features, 'svm', [100], [0], [1e-6])\n",
    "\n",
    "print(\"gs precision:\", cv_precision)\n",
    "print(\"gs recall:\", cv_recall)\n",
    "print(\"gs f-score:\", cv_fscore)\n",
    "print(\"gs hyper:\", cv_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OverSampling ratio = 0.50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100, 0, 1e-06]\n",
      "train: 290040\n",
      "fraud ratio: 0.5\n",
      "train: 290042\n",
      "fraud ratio: 0.5\n",
      "train: 290040\n",
      "fraud ratio: 0.5\n",
      "train: 290040\n",
      "fraud ratio: 0.5\n",
      "train: 290046\n",
      "fraud ratio: 0.5\n",
      "[0.0581038083630286, 0.8735060814383925, 0.10895983504566481]\n",
      "gs precision: 0.0581038083630286\n",
      "gs recall: 0.8735060814383925\n",
      "gs f-score: 0.10895983504566481\n",
      "gs hyper: [100, 0, 1e-06]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V23','V24','V25','V26','V27',\n",
    "                                            'V28','Amount']\n",
    "\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'over', 0.50, False, features, 'svm', [100], [0], [1e-6])\n",
    "\n",
    "print(\"gs precision:\", cv_precision)\n",
    "print(\"gs recall:\", cv_recall)\n",
    "print(\"gs f-score:\", cv_fscore)\n",
    "print(\"gs hyper:\", cv_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) train base_train test base_test using hyperparams from 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampling function-based\n",
    "def sample(df, sampling_method, ratio):\n",
    "\n",
    "    notfraud = df.select('*').where(df.Class == 0.0)\n",
    "    fraud = df.select('*').where(df.Class == 1.0)\n",
    "\n",
    "    if sampling_method == \"over\":\n",
    "        nrows = notfraud.select(\"Class\").count()\n",
    "        sample_size = int(nrows*ratio/(1-ratio))\n",
    "        sampled = fraud.rdd.takeSample(True, sample_size, 46)\n",
    "        fraud = sqlContext.createDataFrame(sampled)\n",
    "\n",
    "    elif sampling_method == \"under\":\n",
    "        nrows = fraud.select(\"Class\").count()\n",
    "        sample_size = int(nrows*(1-ratio)/ratio)\n",
    "        sampled = notfraud.rdd.takeSample(False, sample_size, 46)\n",
    "        notfraud = sqlContext.createDataFrame(sampled)\n",
    "\n",
    "    sampled = fraud.union(notfraud)\n",
    "    fraud_count = sampled.select(\"Class\").where(sampled.Class == 1.0).count()\n",
    "    tot_count = sampled.select(\"Class\").count()\n",
    "    fraud_ratio = fraud_count / tot_count\n",
    "\n",
    "    print(\"train after sampling: \" + str(tot_count))\n",
    "    print(\"fraud ratio: \" + str(fraud_ratio))\n",
    "\n",
    "    #shuffle undersampled dataframe\n",
    "    nrows = sampled.select(\"Class\").count()\n",
    "    shuffled = sampled.rdd.takeSample(False, nrows)\n",
    "    shuffled_df = sqlContext.createDataFrame(shuffled)\n",
    "\n",
    "    return shuffled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train after sampling: 3079\n",
      "fraud ratio: 0.10003247807729783\n",
      "Coefficients: [-0.04749698507864312,-0.01064948165990448,-0.3348078659736613,4.185215838234029,-0.2002936576223215,-0.05546262795000344,-0.6885729392962682,-0.0900824587440696,-0.4353796545090049,-0.6538890286760872,7.223975245027507,-0.9198661304009559,-0.006514236498155325,-1.5045674016375015,-0.003457317905492695,-0.9380861651011605,-0.8822007153616107,-0.496352241120324,0.007625931666285767,-0.09801540259589066,-0.024122262020219668,-0.017363985432215862,-0.21880235435461257,-0.0002601401709577144,-0.034488042084791774,-0.00270021991534686,-0.11810219721848411,-0.27961141511035426,-2.6104743167647197]\n",
      "\n",
      "Intercept: -5.71821797729421e-05\n",
      "EVALUATE PREDICTION ON TEST SET\n",
      "+--------------------+-----+--------------------+----------+\n",
      "|            features|Class|       rawPrediction|prediction|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "|[0.975813201,0.76...|  0.0|[1.94503678431869...|       0.0|\n",
      "|[0.947109992,0.77...|  0.0|[1.97269587019555...|       0.0|\n",
      "|[0.975559578,0.76...|  0.0|[1.19562986636066...|       0.0|\n",
      "|[0.935329608,0.78...|  0.0|[1.98468118788425...|       0.0|\n",
      "|[0.986674528,0.76...|  0.0|[2.00435054862210...|       0.0|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[4.5266e+04 3.9000e+01]\n",
      " [1.9000e+01 7.2000e+01]]\n",
      "\n",
      "Overall Evaluation:\n",
      "Accuracy = 0.9987223543924575\n",
      "fMeasure = 0.9987223543924575\n",
      "precision = 0.9987223543924575\n",
      "recall = 0.9987223543924575\n",
      "Area under Precision Recall Curve = 0.7351110693207419\n",
      "Area under ROC = 0.9841916388434937\n",
      "\n",
      "Class 1 Evaluation:\n",
      "fMeasure = 0.7128712871287128\n",
      "false positive rate = 0.000860832137733142\n",
      "precision = 0.6486486486486487\n",
      "recall = 0.7912087912087912\n",
      "\n",
      "Class 0 Evaluation:\n",
      "fMeasure = 0.9995804350226344\n",
      "false positive rate = 0.2087912087912088\n",
      "precision = 0.9995804350226344\n",
      "recall = 0.9991391678622669\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "training = sample(df, 'under', 0.10)\n",
    "testing = sqlContext.read.csv('base_test.csv', header = True)\n",
    "\n",
    "training = training.select(*(col(c).cast(\"double\").alias(c) for c in training.columns))\n",
    "testing = testing.select(*(col(c).cast(\"double\").alias(c) for c in testing.columns))\n",
    "\n",
    "# Preparing training and test data for model building\n",
    "vectorAssembler =VectorAssembler(inputCols=['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V23','V24','V25','V26','V27',\n",
    "                                            'V28','Amount'],outputCol='features')\n",
    "\n",
    "training_data = vectorAssembler.transform(training).select('features','Class')\n",
    "testing_data = vectorAssembler.transform(testing).select('features','Class')\n",
    "\n",
    "# Build Model\n",
    "lsvc = LinearSVC(maxIter=100, regParam=0, standardization=True, tol=1e-6, threshold=0, aggregationDepth=2,\n",
    "                 featuresCol = 'features', labelCol='Class')\n",
    "\n",
    "# Fit the model on training data\n",
    "lsvcModel  = lsvc.fit(training_data)\n",
    "# Print the coefficients and intercept for linearsSVC\n",
    "print(\"Coefficients: \" + str(lsvcModel.coefficients))\n",
    "print(\"\\nIntercept: \" + str(lsvcModel.intercept))\n",
    "\n",
    "# Compute raw scores on the test set\n",
    "print(\"EVALUATE PREDICTION ON TEST SET\")\n",
    "pred_results = lsvcModel.transform(testing_data)\n",
    "pred_results.show(5)\n",
    "\n",
    "# Convert to RDD and just incliding prediction and class to calculate metrics\n",
    "predictionAndLabels = pred_results.select('Class','prediction').rdd.map(lambda lp: (float(lp.prediction), lp.Class))\n",
    "\n",
    "# To print RDD\n",
    "#print(predictionAndLabels.collect())\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(\"\\nOverall Evaluation:\")\n",
    "print(\"Accuracy = %s\" % metrics.accuracy)\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure())\n",
    "print(\"precision = %s\" % metrics.precision())\n",
    "print(\"recall = %s\" % metrics.recall())\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Class\",metricName=\"areaUnderPR\")\n",
    "print(\"Area under Precision Recall Curve = %s\" % evaluator.evaluate(pred_results))\n",
    "evaluator=  BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Class\",metricName=\"areaUnderROC\")\n",
    "print(\"Area under ROC = %s\" % evaluator.evaluate(pred_results))\n",
    "\n",
    "print(\"\\nClass 1 Evaluation:\")\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure(1.0,1.0))\n",
    "print(\"false positive rate = %s\" % metrics.falsePositiveRate(1.0))\n",
    "print(\"precision = %s\" % metrics.precision(1.0))\n",
    "print(\"recall = %s\" % metrics.recall(1.0))\n",
    "\n",
    "print(\"\\nClass 0 Evaluation:\")\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure(0.0,0.0))\n",
    "print(\"false positive rate = %s\" % metrics.falsePositiveRate(0.0))\n",
    "print(\"precision = %s\" % metrics.precision(0.0))\n",
    "print(\"recall = %s\" % metrics.recall(0.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) train base_train test oot using hyperparams from 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATE PREDICTION ON TEST SET\n",
      "+--------------------+-----+--------------------+----------+\n",
      "|            features|Class|       rawPrediction|prediction|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "|[0.99380842121992...|  0.0|[2.34682596842262...|       0.0|\n",
      "|[0.96072303825523...|  0.0|[2.19614890771865...|       0.0|\n",
      "|[0.99248737657781...|  0.0|[1.20905331550666...|       0.0|\n",
      "|[0.92658813030988...|  0.0|[0.70187605896471...|       0.0|\n",
      "|[0.99344967061734...|  0.0|[2.10630661321926...|       0.0|\n",
      "+--------------------+-----+--------------------+----------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Confusion Matrix:\n",
      "\n",
      "[[5.6652e+04 2.0000e+01]\n",
      " [2.6000e+01 4.8000e+01]]\n",
      "\n",
      "Overall Evaluation:\n",
      "Accuracy = 0.9991893701758714\n",
      "fMeasure = 0.9991893701758714\n",
      "precision = 0.9991893701758714\n",
      "recall = 0.9991893701758714\n",
      "Area under Precision Recall Curve = 0.7079254026104055\n",
      "Area under ROC = 0.9588084873411391\n",
      "\n",
      "Class 1 Evaluation:\n",
      "fMeasure = 0.676056338028169\n",
      "false positive rate = 0.00035290796160361375\n",
      "precision = 0.7058823529411765\n",
      "recall = 0.6486486486486487\n",
      "\n",
      "Class 0 Evaluation:\n",
      "fMeasure = 0.9995412682169449\n",
      "false positive rate = 0.35135135135135137\n",
      "precision = 0.9995412682169449\n",
      "recall = 0.9996470920383964\n"
     ]
    }
   ],
   "source": [
    "testing = sqlContext.read.csv('oot.csv', header = True)\n",
    "testing = testing.select(*(col(c).cast(\"double\").alias(c) for c in testing.columns))\n",
    "# Preparing training and test data for model building\n",
    "vectorAssembler =VectorAssembler(inputCols=['V1','V2','V3','V4','V5','V6','V7','V8','V9',\n",
    "                                            'V10','V11','V12','V13','V14','V15','V16','V17','V18',\n",
    "                                            'V19','V20','V21','V22','V23','V24','V25','V26','V27',\n",
    "                                            'V28','Amount'],outputCol='features')\n",
    "testing_data = vectorAssembler.transform(testing).select('features','Class')\n",
    "# Compute raw scores on the test set\n",
    "print(\"EVALUATE PREDICTION ON TEST SET\")\n",
    "pred_results = lsvcModel.transform(testing_data)\n",
    "pred_results.show(5)\n",
    "\n",
    "# Convert to RDD and just incliding prediction and class to calculate metrics\n",
    "predictionAndLabels = pred_results.select('Class','prediction').rdd.map(lambda lp: (float(lp.prediction), lp.Class))\n",
    "\n",
    "# To print RDD\n",
    "#print(predictionAndLabels.collect())\n",
    "\n",
    "# Instantiate metrics object\n",
    "metrics = MulticlassMetrics(predictionAndLabels)\n",
    "print(\"Confusion Matrix:\\n\")\n",
    "print(metrics.confusionMatrix().toArray())\n",
    "print(\"\\nOverall Evaluation:\")\n",
    "print(\"Accuracy = %s\" % metrics.accuracy)\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure())\n",
    "print(\"precision = %s\" % metrics.precision())\n",
    "print(\"recall = %s\" % metrics.recall())\n",
    "evaluator = BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Class\",metricName=\"areaUnderPR\")\n",
    "print(\"Area under Precision Recall Curve = %s\" % evaluator.evaluate(pred_results))\n",
    "evaluator=  BinaryClassificationEvaluator(rawPredictionCol=\"rawPrediction\", labelCol=\"Class\",metricName=\"areaUnderROC\")\n",
    "print(\"Area under ROC = %s\" % evaluator.evaluate(pred_results))\n",
    "\n",
    "print(\"\\nClass 1 Evaluation:\")\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure(1.0,1.0))\n",
    "print(\"false positive rate = %s\" % metrics.falsePositiveRate(1.0))\n",
    "print(\"precision = %s\" % metrics.precision(1.0))\n",
    "print(\"recall = %s\" % metrics.recall(1.0))\n",
    "\n",
    "print(\"\\nClass 0 Evaluation:\")\n",
    "print(\"fMeasure = %s\" % metrics.fMeasure(0.0,0.0))\n",
    "print(\"false positive rate = %s\" % metrics.falsePositiveRate(0.0))\n",
    "print(\"precision = %s\" % metrics.precision(0.0))\n",
    "print(\"recall = %s\" % metrics.recall(0.0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
