{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Factory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries for modeling\n",
    "from multiprocessing.pool import ThreadPool\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext, SparkSession, Window, Row\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "import pyspark.sql.functions as F\n",
    "import itertools\n",
    "from itertools import repeat\n",
    "import pickle\n",
    "import pyspark\n",
    "import copy\n",
    "\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.classification import GBTClassifier\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "#libraries for plotting\n",
    "import matplotlib.gridspec as gridspec\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class CreateBestModel:\n",
    "    def __init__(self, algo, avgprecision, avgrecall, avgfscore, hyperparams, ootmodel, ootprecision, ootrecall, ootfscore):\n",
    "        self.algo = algo\n",
    "        self.gsPrecision = avgprecision\n",
    "        self.gsFScore = avgfscore\n",
    "        self.gsRecall = avgrecall\n",
    "        self.hyperParams = hyperparams\n",
    "        self.model = ootmodel\n",
    "        self.ootPrecision = ootprecision\n",
    "        self.ootFScore = ootfscore\n",
    "        self.ootRecall = ootrecall\n",
    "\n",
    "#function-based\n",
    "def sample(df, sampling_method, ratio):\n",
    "\n",
    "    notfraud = df.select('*').where(df.Class == 0.0)\n",
    "    fraud = df.select('*').where(df.Class == 1.0)\n",
    "\n",
    "    if sampling_method == \"over\":\n",
    "        nrows = notfraud.select(\"Class\").count()\n",
    "        sample_size = int(nrows*ratio/(1-ratio))\n",
    "        sampled = fraud.rdd.takeSample(True, sample_size, 46)\n",
    "        fraud = sqlContext.createDataFrame(sampled)\n",
    "\n",
    "    elif sampling_method == \"under\":\n",
    "        nrows = fraud.select(\"Class\").count()\n",
    "        sample_size = int(nrows*(1-ratio)/ratio)\n",
    "        sampled = notfraud.rdd.takeSample(False, sample_size, 46)\n",
    "        notfraud = sqlContext.createDataFrame(sampled)\n",
    "\n",
    "    sampled = fraud.union(notfraud)\n",
    "    fraud_count = sampled.select(\"Class\").where(sampled.Class == 1.0).count()\n",
    "    tot_count = sampled.select(\"Class\").count()\n",
    "    fraud_ratio = fraud_count / tot_count\n",
    "\n",
    "    print(\"train after sampling: \" + str(tot_count))\n",
    "    print(\"fraud ratio: \" + str(fraud_ratio))\n",
    "\n",
    "    #shuffle undersampled dataframe\n",
    "    nrows = sampled.select(\"Class\").count()\n",
    "    shuffled = sampled.rdd.takeSample(False, nrows, 46)\n",
    "    shuffled_df = sqlContext.createDataFrame(shuffled)\n",
    "\n",
    "    return shuffled_df\n",
    "\n",
    "def generateParamGrid(*args):\n",
    "    \n",
    "    grid = list(itertools.product(*args))\n",
    "    return grid\n",
    "\n",
    "def generateClassifier(algo, params, features):\n",
    "\n",
    "    ############################################################################\n",
    "    #TODO: complete this section\n",
    "\n",
    "    def lr(params,features):\n",
    "        print(params)\n",
    "        if len(params) > 2:\n",
    "            lrClassifier = LogisticRegression(featuresCol = 'features',\n",
    "                                          labelCol = 'Class',\n",
    "                                          threshold=params[0],\n",
    "                                           maxIter=params[1],\n",
    "                                           weightCol=params[2])\n",
    "                                          #regParam=params[2])\n",
    "                                          #elasticNetParam=params[2])\n",
    "        else:\n",
    "            lrClassifier = LogisticRegression(featuresCol = 'features',\n",
    "                                          labelCol = 'Class',\n",
    "                                          threshold=params[0],\n",
    "                                           maxIter=params[1])\n",
    "        return lrClassifier\n",
    "\n",
    "\n",
    "    def gbm(params,features):\n",
    "        gbmClassifier = GBTClassifier(featuresCol = 'features',\n",
    "                                      labelCol = 'Class',\n",
    "                                      maxDepth = params[0],\n",
    "                                      maxIter = params[1],\n",
    "                                     stepSize = params[2])\n",
    "        return gbmClassifier\n",
    "\n",
    "    def rf(params,features):\n",
    "        rfClassifier = RandomForestClassifier(featuresCol='features',\n",
    "                                              labelCol='Class',\n",
    "                                              maxDepth=params[0],\n",
    "                                              minInfoGain=params[1],\n",
    "                                              numTrees=params[2])\n",
    "\n",
    "        return rfClassifier\n",
    "\n",
    "    def mlp(params,features):\n",
    "        input_layers = len(features)\n",
    "        layers = [input_layers, params[1], 2]\n",
    "        print(layers)\n",
    "        mlpClassifier = MultilayerPerceptronClassifier(featuresCol = 'features',\n",
    "                                                       labelCol = 'Class',\n",
    "                                                       maxIter = params[0],\n",
    "                                                       layers = layers,\n",
    "                                                       stepSize = params[2])\n",
    "        return mlpClassifier\n",
    "\n",
    "    def svm(params, features):\n",
    "        svmClassifier = LinearSVC(featuresCol = 'features',\n",
    "                         labelCol='Class', \n",
    "                         standardization=True,\n",
    "                         maxIter=params[0],\n",
    "                         regParam=params[1],\n",
    "                         tol =params[2]\n",
    "                         )\n",
    "        \n",
    "        return svmClassifier\n",
    "\n",
    "    def xg(params,features):\n",
    "        return\n",
    "    ############################################################################\n",
    "\n",
    "    getClassifier = {\n",
    "        'lr':lr,\n",
    "        'gbm':gbm,\n",
    "        'rf':rf,\n",
    "        'mlp':mlp,\n",
    "        'svm':svm,\n",
    "        'xg':xg}\n",
    "\n",
    "    return getClassifier[algo](params,features)\n",
    "\n",
    "def crossValidate(df, folds, k, classifier, features, sampling_method, ratio, pool):\n",
    "\n",
    "    def build(fold, df, classifier, features, sampling_method, ratio):\n",
    "\n",
    "        #undersample notfraud\n",
    "        validation = fold\n",
    "        train = df.subtract(fold)\n",
    "\n",
    "#         #add class weight\n",
    "#         notfraud_count = train.select(\"Class\").where(train.Class == 0.0).count()\n",
    "#         total_count = train.select(\"Class\").count()\n",
    "#         balance_ratio = notfraud_count / total_count\n",
    "#         train=train.withColumn(\"classWeights\", F.when(train.Class == 1.0,balance_ratio).otherwise(1-balance_ratio))\n",
    "        \n",
    "        train = sample(train, sampling_method, ratio)\n",
    "        vectorAssembler = VectorAssembler(inputCols = features, outputCol = 'features')\n",
    "        vector_train = vectorAssembler.transform(train)\n",
    "        vector_validate = vectorAssembler.transform(validation)\n",
    "        model = classifier.fit(vector_train)\n",
    "        pred = model.transform(vector_validate)\n",
    "        pos = pred.filter(pred.prediction == 1.0).count()\n",
    "        if pos != 0:\n",
    "            precision = pred.filter(pred.Class == pred.prediction).filter(pred.Class == 1.0).count() / pos\n",
    "        else:\n",
    "            precision = 0\n",
    "        fraud = pred.filter(pred.Class == 1.0).count()\n",
    "        if fraud != 0:\n",
    "            recall = pred.filter(pred.Class == pred.prediction).filter(pred.Class == 1.0).count() / fraud\n",
    "        else:\n",
    "            recall = 0\n",
    "        precision_recall = precision + recall\n",
    "        if precision_recall != 0:\n",
    "            f_score = 2 * precision * recall /(precision_recall)\n",
    "        else:\n",
    "            f_score = 0\n",
    "        #print(\"\\n precision, recall, f_score: \" + str(precision) + \", \" + str(recall) + \", \" + str(f_score))\n",
    "        return [precision, recall, f_score]\n",
    "\n",
    "    #call multiprocessing here\n",
    "    cvperformance = pool.map(lambda fold: build(fold, df, classifier, features, sampling_method, ratio), folds)\n",
    "\n",
    "    #calculate metrics\n",
    "    precision_sum = sum([x[0] for x in cvperformance])\n",
    "    recall_sum = sum([x[1] for x in cvperformance])\n",
    "\n",
    "    avg_precision = precision_sum/k\n",
    "    avg_recall = recall_sum/k\n",
    "    if avg_precision+avg_recall == 0:\n",
    "        avg_fscore = 0\n",
    "    else:\n",
    "        avg_fscore = 2 * avg_precision * avg_recall /(avg_precision+avg_recall)\n",
    "    return [avg_precision,avg_recall,avg_fscore]\n",
    "\n",
    "def gridSearch(df, folds, k, algo, grid, features, sampling_method, ratio, pool):\n",
    "\n",
    "    best_hyper = None\n",
    "    best_precision = 0\n",
    "    best_recall = 0\n",
    "    best_fscore = 0\n",
    "\n",
    "    for i in range(len(grid)):\n",
    "        params = list(grid[i])\n",
    "        print(params)\n",
    "        classifier = generateClassifier(algo, params, features)\n",
    "        modelPerformance = crossValidate(df, folds, k, classifier, features, sampling_method, ratio, pool)\n",
    "        print(modelPerformance)\n",
    "        if modelPerformance[2] > best_fscore:\n",
    "            best_hyper = params\n",
    "            best_precision = modelPerformance[0]\n",
    "            best_recall = modelPerformance[1]\n",
    "            best_fscore = modelPerformance[2]\n",
    "\n",
    "    return best_hyper, best_precision, best_recall, best_fscore\n",
    "\n",
    "def ootTest(traindf,testdf, algo,features,params):\n",
    "    vectorAssembler = VectorAssembler(inputCols = features, outputCol = 'features')\n",
    "    classifier = generateClassifier(algo, params, features)\n",
    "    vector_train = vectorAssembler.transform(traindf)\n",
    "    vector_test = vectorAssembler.transform(testdf)\n",
    "    ootmodel = classifier.fit(vector_train)\n",
    "    pred = ootmodel.transform(vector_test)\n",
    "    pos = pred.filter(pred.prediction == 1.0).count()\n",
    "    if pos != 0:\n",
    "        precision = pred.filter(pred.Class == pred.prediction).filter(pred.Class == 1.0).count() / pos\n",
    "    else:\n",
    "        precision = 0\n",
    "    fraud = pred.filter(pred.Class == 1.0).count()\n",
    "    if fraud != 0:\n",
    "        recall = pred.filter(pred.Class == pred.prediction).filter(pred.Class == 1.0).count() / fraud\n",
    "    else:\n",
    "        recall = 0\n",
    "    precision_recall = precision + recall\n",
    "    if precision_recall != 0:\n",
    "        f_score = 2 * precision * recall /(precision_recall)\n",
    "    else:\n",
    "        f_score = 0\n",
    "    print(\"\\n precision, recall, f_score: \" + str(precision) + \", \" + str(recall) + \", \" + str(f_score))\n",
    "    \n",
    "    return ootmodel, precision, recall, f_score\n",
    "\n",
    "def tune(df, k, stratification_flag, sampling_method, ratio, modelobj_flag, features, algo, *args, **kwargs):\n",
    "\n",
    "    \"\"\"\n",
    "    Entry point of this suite of functions. returns cv metrics or a model object\n",
    "    Example:\n",
    "        >>> cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True,\n",
    "        'None', 0, False, features, 'mlp', [100], [15], [0.03])\n",
    "    :param df: data for modeling purpose\n",
    "    :type df: : pyspark dataframe\n",
    "    :param k: number of folds for cross validation\n",
    "    :type k: int\n",
    "    :param stratification_flag: specifies whether fraud ratio is fixed for each fold. True for stratification\n",
    "    :type stratification_flag: boolean\n",
    "    :param sampling_method: \"over\" for oversampling minority class, \"under\" for undersampling majority class, \"None\"\n",
    "    :type sampling_method: str\n",
    "    :param ratio: targeted fraud ratio after sampling.\n",
    "    :type ratio: float\n",
    "    :param modelobj_flag: specifies whether to return a model object for out of time test. if False, returns cv performancce\n",
    "    :type modelobj_flag: float\n",
    "    :param features: features for training\n",
    "    :type features: list\n",
    "    :param *args: a sequence of params for hyperparams tuning. ex. [values for params1], [values for params2],...\n",
    "    :type *args: list\n",
    "    :returns: model object or cross validation metrics depending on modelobj_flag\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    pool = ThreadPool(3)\n",
    "\n",
    "    #reduce df dimenions to include features and class\n",
    "    cols = features+['Class', 'index']\n",
    "    df = df.select(cols)\n",
    "    df = df.select(*(F.col(c).cast(\"double\").alias(c) for c in df.columns))\n",
    "    df.cache()\n",
    "    #df.drop(\"index\")\n",
    "    \n",
    "    ########################ClassWeights#################################\n",
    "    if algo in [\"lr\", \"svm\"] and [\"ClassWeigts\"] in args:\n",
    "        #add class weight\n",
    "        balance_ratio = args[-1][0]\n",
    "        df=df.withColumn(\"classWeights\", when(df.Class == 1.0,balance_ratio).otherwise(1-balance_ratio))\n",
    "    ########################ClassWeights#################################\n",
    "    \n",
    "    folds = []\n",
    "    \n",
    "    if stratification_flag == False:\n",
    "        tot_count = df.select(\"Class\").count()\n",
    "        n = int(tot_count / k)\n",
    "\n",
    "        #create sub-dataframe iteratively\n",
    "        fold_start = 1\n",
    "        fold_end = n\n",
    "        for i in range(k):\n",
    "            fold = df.select('*').where(df.index.between(fold_start, fold_end))\n",
    "            folds.append(fold)\n",
    "            fold_start = fold_end + 1\n",
    "            fold_end = fold_start + n\n",
    "            if i == k-2:\n",
    "                end = tot_count\n",
    "                \n",
    "    if stratification_flag == True:\n",
    "        fraud = df.select(\"*\").where(df.Class == 1.0)\n",
    "        #shuffle undersampled dataframe\n",
    "        nrows = fraud.select(\"Class\").count()\n",
    "        shuffled = fraud.rdd.takeSample(False, nrows, 46)\n",
    "        fraud = sqlContext.createDataFrame(shuffled)\n",
    "        #add row index to dataframe\n",
    "        fraud = fraud.withColumn('dummy', F.lit('7'))\n",
    "        fraud = fraud.withColumn(\"temp_index\", F.row_number().over(Window.partitionBy(\"dummy\").orderBy(\"dummy\")))\n",
    "        fraud = fraud.drop('dummy')\n",
    "        fraud_count = fraud.select(\"Class\").count()\n",
    "        each_fraud = int(fraud_count/k)\n",
    "\n",
    "        notfraud = df.select(\"*\").where(df.Class == 0.0)\n",
    "        nrows = notfraud.select(\"Class\").count()\n",
    "        shuffled = notfraud.rdd.takeSample(False, nrows, 46)\n",
    "        notfraud = sqlContext.createDataFrame(shuffled)\n",
    "        #add row index to dataframe\n",
    "        notfraud = notfraud.withColumn('dummy', F.lit('7'))\n",
    "        notfraud = notfraud.withColumn(\"temp_index\", F.row_number().over(Window.partitionBy(\"dummy\").orderBy(\"dummy\")))\n",
    "        notfraud = notfraud.drop('dummy')\n",
    "        notfraud_count = notfraud.select(\"Class\").count()\n",
    "        each_notfraud = int(notfraud_count/k)\n",
    "\n",
    "        fraud_start = 1\n",
    "        fraud_end = each_fraud\n",
    "        notfraud_start = 1\n",
    "        notfraud_end = each_notfraud\n",
    "\n",
    "        for i in range(k):\n",
    "            fraud_fold  = fraud.select('*').where(fraud.temp_index.between(fraud_start, fraud_end))\n",
    "            notfraud_fold = notfraud.select('*').where(notfraud.temp_index.between(notfraud_start, notfraud_end))\n",
    "            fold = fraud_fold.union(notfraud_fold).drop(\"temp_index\")\n",
    "            folds.append(fold)\n",
    "            fraud_start = fraud_end + 1\n",
    "            fraud_end = fraud_start + each_fraud\n",
    "            notfraud_start = notfraud_end + 1\n",
    "            notfraud_end = notfraud_start + each_notfraud\n",
    "            if i == k-2:\n",
    "                fraud_end = fraud_count\n",
    "                notfraud_end = notfraud_count\n",
    "\n",
    "\n",
    "    #generate hyperparam combo\n",
    "    grid = generateParamGrid(*args)\n",
    "\n",
    "    #conduct grid search:\n",
    "    best_hyper, best_precision, best_recall, best_fscore = gridSearch(df, folds, k, algo, grid, features, sampling_method, ratio, pool)\n",
    "\n",
    "    if modelobj_flag == True:\n",
    "        #generate a model obj\n",
    "        traindf = sample(df, sampling_method, ratio)\n",
    "        testdf = sqlContext.read.csv(\"oot.csv\", header = True)\n",
    "        cols = features+['Class', 'index']\n",
    "        testdf = testdf.select(cols)\n",
    "        testdf = testdf.select(*(F.col(c).cast(\"double\").alias(c) for c in testdf.columns))\n",
    "        model, precision, recall, fscore = ootTest(traindf, testdf, algo,features,best_hyper)\n",
    "        \n",
    "        modelobj = CreateBestModel(algo, best_precision, best_recall, best_fscore, best_hyper, \n",
    "                                   model, precision, recall, fscore)\n",
    "        return modelobj\n",
    "\n",
    "    return best_hyper, best_precision, best_recall, best_fscore\n",
    "\n",
    "def save(content, filename):\n",
    "\n",
    "    pickle.dump(content, open(filename, \"wb\"))\n",
    "\n",
    "def load(filename):\n",
    "\n",
    "    content = pickle.load(open(filename, \"rb\"))\n",
    "    return content\n",
    "\n",
    "def generateStratifiedFolds(df,k):\n",
    "\n",
    "    return folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=pyspark.SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Default Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Spark session\n",
    "sc=pyspark.SparkContext.getOrCreate()\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "#read file as dataframe\n",
    "train_df= sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('base_train.csv')\n",
    "test_df= sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('base_test.csv')\n",
    "\n",
    "vectorAssembler = VectorAssembler(inputCols = ['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19','V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount'], outputCol = 'features')\n",
    "train_df_v = vectorAssembler.transform(train_df)\n",
    "test_df_v = vectorAssembler.transform(test_df)\n",
    "gbt = GBTClassifier(featuresCol = 'features',labelCol = 'Class')\n",
    "\n",
    "gbt_model = gbt.fit(train_df_v)\n",
    "gbt_prediction = gbt_model.transform(test_df_v)\n",
    "gbt_prediction.select('features','Class','prediction').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is  0.922077922077922\n",
      "Recall is  0.7802197802197802\n",
      "F1 score is  0.8452380952380951\n",
      "Test Area Under ROC: 0.9847701355040529\n"
     ]
    }
   ],
   "source": [
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Class\", metricName=\"areaUnderROC\")\n",
    "area = evaluator.evaluate(gbt_prediction)\n",
    "pred = gbt_prediction\n",
    "precision = pred.filter(pred.Class == pred.prediction).filter(pred.Class == 1.0).count() / pred.filter(pred.prediction == 1.0).count()\n",
    "recall = pred.filter(pred.Class == pred.prediction).filter(pred.Class == 1.0).count() / pred.filter(pred.Class == 1.0).count()\n",
    "f1 = 2 * precision * recall /(precision + recall)\n",
    "print(\"Precision is \", precision)\n",
    "print(\"Recall is \", recall)\n",
    "print(\"F1 score is \", f1)\n",
    "print(\"Test Area Under ROC: \" + str(area))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Compare random cv and stratified cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 20]\n",
      "train after sampling: 152562\n",
      "fraud ratio: 0.0014420366801693738\n",
      "train after sampling: 152482\n",
      "fraud ratio: 0.0016592122348867407\n",
      "\n",
      " precision, recall, f_score: 0.8837209302325582, 0.6909090909090909, 0.7755102040816326\n",
      "\n",
      " precision, recall, f_score: 0.49, 0.5568181818181818, 0.5212765957446808\n",
      "train after sampling: 152538\n",
      "fraud ratio: 0.0017372720240202441\n",
      "train after sampling: 152553\n",
      "fraud ratio: 0.0018223174896593315\n",
      "\n",
      " precision, recall, f_score: 1.0, 0.6511627906976745, 0.7887323943661972\n",
      "\n",
      " precision, recall, f_score: 0.8947368421052632, 0.5666666666666667, 0.6938775510204083\n",
      "train after sampling: 152499\n",
      "fraud ratio: 0.0016655846923586384\n",
      "\n",
      " precision, recall, f_score: 0.8163265306122449, 0.7407407407407407, 0.7766990291262137\n",
      "grids search precision: 0.8169568605900132\n",
      "grids search recall: 0.6412594941664709\n",
      "grids search f-score: 0.7185234776293068\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19','V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount']\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, False, 'None', 0, False, features, 'gbm', [5],[20])\n",
    "print(\"grids search precision:\", cv_precision)\n",
    "print(\"grids search recall:\", cv_recall)\n",
    "print(\"grids search f-score:\", cv_fscore)\n",
    "sqlContext.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratified CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 20]\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "\n",
      " precision, recall, f_score: 0.9074074074074074, 0.7903225806451613, 0.8448275862068966\n",
      "\n",
      " precision, recall, f_score: 0.9019607843137255, 0.7540983606557377, 0.8214285714285715\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "\n",
      " precision, recall, f_score: 0.8679245283018868, 0.7419354838709677, 0.8\n",
      "\n",
      " precision, recall, f_score: 0.8888888888888888, 0.6451612903225806, 0.7476635514018692\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "\n",
      " precision, recall, f_score: 0.8679245283018868, 0.7540983606557377, 0.8070175438596491\n",
      "grid search precision: 0.8868212274427589\n",
      "grid search recall: 0.737123215230037\n",
      "grid search f-score: 0.805072510277454\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['Amount', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', \n",
    "            'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', \n",
    "            'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', \n",
    "            'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28']\n",
    "\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'None', 0, False, features, 'gbm', [5],[20])\n",
    "print(\"grid search precision:\", cv_precision)\n",
    "print(\"grid search recall:\", cv_recall)\n",
    "print(\"grid search f-score:\", cv_fscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 50, 0.1]\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "\n",
      " precision, recall, f_score: 0.9523809523809523, 0.6451612903225806, 0.7692307692307692\n",
      "\n",
      " precision, recall, f_score: 0.9215686274509803, 0.7704918032786885, 0.8392857142857142\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.9326188240172704, 0.7534108937070332, 0.8334908623547159]\n",
      "[4, 50, 0.05]\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.9256353926547864, 0.7403490216816498, 0.8226886776234749]\n",
      "[4, 100, 0.1]\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.9376742272775104, 0.7695928080380751, 0.8453596615740194]\n",
      "[4, 100, 0.05]\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.9478187837986978, 0.7501322051824431, 0.8374675111569493]\n",
      "[4, 200, 0.1]\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.9378856437679968, 0.7728186144896879, 0.8473884135937805]\n",
      "[4, 200, 0.05]\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.9415156695156697, 0.7728186144896879, 0.848866924058035]\n",
      "[5, 50, 0.1]\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.9175755416068112, 0.7598625066102591, 0.8313049197741721]\n",
      "[5, 50, 0.05]\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.8904449541192839, 0.7533580116340559, 0.8161852169398531]\n",
      "[5, 100, 0.1]\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.9324376037030575, 0.7631411951348492, 0.8393376323958763]\n",
      "[5, 100, 0.05]\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.9035679237878727, 0.7533580116340559, 0.8216542693778334]\n",
      "[5, 200, 0.1]\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.9330338757990303, 0.7695928080380752, 0.8434687031364799]\n",
      "[5, 200, 0.05]\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.9177046896053108, 0.7533580116340559, 0.8274497177341683]\n",
      "grids search precision: 0.9415156695156697\n",
      "grids search recall: 0.7728186144896879\n",
      "grids search f-score: 0.848866924058035\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19','V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount']\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'None', 0, False, features, 'gbm', [4,5],[50, 100, 200],[0.1, 0.05])\n",
    "print(\"grids search precision:\", cv_precision)\n",
    "print(\"grids search recall:\", cv_recall)\n",
    "print(\"grids search f-score:\", cv_fscore)\n",
    "sqlContext.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare cross validation using default and best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 20, 0.1]\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.889746826686701, 0.7272871496562664, 0.8003560134959474]\n",
      "grids search precision: 0.889746826686701\n",
      "grids search recall: 0.7272871496562664\n",
      "grids search f-score: 0.8003560134959474\n"
     ]
    }
   ],
   "source": [
    "# Default params\n",
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19','V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount']\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'None', 0, False, features, 'gbm', [5],[20],[0.1])\n",
    "print(\"grids search precision:\", cv_precision)\n",
    "print(\"grids search recall:\", cv_recall)\n",
    "print(\"grids search f-score:\", cv_fscore)\n",
    "sqlContext.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 200, 0.1]\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.9354317307981658, 0.7759915388683236, 0.8482847243625291]\n",
      "grids search precision: 0.9354317307981658\n",
      "grids search recall: 0.7759915388683236\n",
      "grids search f-score: 0.8482847243625291\n"
     ]
    }
   ],
   "source": [
    "# Best Params\n",
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19','V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount']\n",
    "cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'None', 0, False, features, 'gbm', [4],[200],[0.1])\n",
    "print(\"grids search precision:\", cv_precision)\n",
    "print(\"grids search recall:\", cv_recall)\n",
    "print(\"grids search f-score:\", cv_fscore)\n",
    "sqlContext.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 200, 0.05]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_hyper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using [4, 200, 0.1] is almost the same as [4,200,0.05] so stick with former for faster training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improve base model with optimized hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is  0.9506172839506173\n",
      "Recall is  0.8461538461538461\n",
      "F1 score is  0.8953488372093024\n",
      "Test Area Under ROC: 0.9780428378596705\n"
     ]
    }
   ],
   "source": [
    "gbt = GBTClassifier(featuresCol = 'features',labelCol = 'Class', maxDepth = 4, maxIter = 200, stepSize = 0.1)\n",
    "gbt_model = gbt.fit(train_df_v)\n",
    "gbt_prediction = gbt_model.transform(test_df_v)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Class\", metricName=\"areaUnderROC\")\n",
    "area = evaluator.evaluate(gbt_prediction)\n",
    "pred = gbt_prediction\n",
    "precision = pred.filter(pred.Class == pred.prediction).filter(pred.Class == 1.0).count() / pred.filter(pred.prediction == 1.0).count()\n",
    "recall = pred.filter(pred.Class == pred.prediction).filter(pred.Class == 1.0).count() / pred.filter(pred.Class == 1.0).count()\n",
    "f1 = 2 * precision * recall /(precision + recall)\n",
    "print(\"Precision is \", precision)\n",
    "print(\"Recall is \", recall)\n",
    "print(\"F1 score is \", f1)\n",
    "print(\"Test Area Under ROC: \" + str(area))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step4: Feature Selection with best hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28],[0.0822596541994895,0.00945299461360841,0.034126595663567946,0.06807104510749665,0.009587266814040282,0.016545083863433407,0.054434972379176466,0.015335562011043717,0.019192738502418732,0.05691123499268879,0.033877205806948134,0.04796141768970416,0.03268011176153309,0.0681275783529924,0.021612317103607993,0.04524086004605648,0.03859509944013328,0.01051431189673979,0.016508482362895066,0.03386908299300409,0.028996681582625458,0.018712669533998336,0.011333105089996671,0.01227696827653833,0.02651539069084511,0.07206483015364591,0.004712223652012938,0.030493319395722848,0.07999119602403588])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = ['Amount', 'V1', 'V2', 'V3', 'V4', 'V5', 'V6', \n",
    "            'V7', 'V8', 'V9', 'V10', 'V11', 'V12', 'V13', \n",
    "            'V14', 'V15', 'V16', 'V17', 'V18', 'V19', 'V20', \n",
    "            'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28']\n",
    "featureImportance = gbt_model.featureImportances\n",
    "print(featureImportance)\n",
    "tmp = pd.DataFrame({'Feature': features, 'Feature importance': featureImportance})\n",
    "tmp = tmp.sort_values(by='Feature importance',ascending=False)\n",
    "plt.figure(figsize = (15,8))\n",
    "plt.title('Features importance',fontsize=14)\n",
    "s = sns.barplot(x='Feature',y='Feature importance',data=tmp)\n",
    "s.set_xticklabels(s.get_xticklabels(),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step5. stratified cv with top features and best hyperparams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combo1: Amount ~ V24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 200, 0.1]\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.9061642612706443, 0.7339502908514014, 0.8110159406344248]\n",
      "grid search precision: 0.9061642612706443\n",
      "grid search recall: 0.7339502908514014\n",
      "grid search f-score: 0.8110159406344248\n",
      "grid search hyper: [4, 200, 0.1]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['Amount', 'V28', 'V25', 'V13', 'V3', 'V9', 'V6', 'V11', 'V15', 'V16', 'V2', 'V10', 'V19', 'V12', 'V27', 'V20', 'V24']\n",
    "gs_hyper, gs_precision, gs_recall, gs_fscore = tune(df, 5, True, 'None', 0, False, features, 'gbm', [4], [200], [0.1])\n",
    "print(\"grid search precision:\", gs_precision)\n",
    "print(\"grid search recall:\", gs_recall)\n",
    "print(\"grid search f-score:\", gs_fscore)\n",
    "print(\"grid search hyper:\", gs_hyper)\n",
    "\n",
    "sqlContext.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combo2: Amount ~ V16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 200, 0.1]\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.920931552772441, 0.7047065044949763, 0.7984390529393709]\n",
      "grid search precision: 0.920931552772441\n",
      "grid search recall: 0.7047065044949763\n",
      "grid search f-score: 0.7984390529393709\n",
      "grid search hyper: [4, 200, 0.1]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['Amount', 'V28', 'V25', 'V13', 'V3', 'V9', 'V6', 'V11', 'V15', 'V16']\n",
    "gs_hyper, gs_precision, gs_recall, gs_fscore = tune(df, 5, True, 'None', 0, False, features, 'gbm', [4], [200], [0.1])\n",
    "print(\"grid search precision:\", gs_precision)\n",
    "print(\"grid search recall:\", gs_recall)\n",
    "print(\"grid search f-score:\", gs_fscore)\n",
    "print(\"grid search hyper:\", gs_hyper)\n",
    "\n",
    "sqlContext.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combo3: Amount ~ V7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 200, 0.1]\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.9204787369493254, 0.7500264410364885, 0.8265564216404091]\n",
      "grid search precision: 0.9204787369493254\n",
      "grid search recall: 0.7500264410364885\n",
      "grid search f-score: 0.8265564216404091\n",
      "grid search hyper: [4, 200, 0.1]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['Amount', 'V28', 'V25', 'V13', 'V3', 'V9', 'V6', 'V11', 'V15', 'V16', 'V2', 'V10', 'V19', 'V12', 'V27', 'V20', 'V24', 'V14', 'V8', 'V21', 'V5', 'V18', 'V7']\n",
    "gs_hyper, gs_precision, gs_recall, gs_fscore = tune(df, 5, True, 'None', 0, False, features, 'gbm', [4], [200], [0.1])\n",
    "print(\"grid search precision:\", gs_precision)\n",
    "print(\"grid search recall:\", gs_recall)\n",
    "print(\"grid search f-score:\", gs_fscore)\n",
    "print(\"grid search hyper:\", gs_hyper)\n",
    "\n",
    "sqlContext.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combo4: Amount ~ V1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 200, 0.1]\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.9382606767230968, 0.7694870438921206, 0.8455340631598475]\n",
      "grid search precision: 0.9382606767230968\n",
      "grid search recall: 0.7694870438921206\n",
      "grid search f-score: 0.8455340631598475\n",
      "grid search hyper: [4, 200, 0.1]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['Amount', 'V28', 'V25', 'V13', 'V3', 'V9', 'V6', 'V11', 'V15', 'V16', 'V2', 'V10', 'V19', 'V12', 'V27', 'V20', 'V24', 'V14', 'V8', 'V21', 'V5', 'V18', 'V7','V23', 'V22', 'V17','V4', 'V1']\n",
    "gs_hyper, gs_precision, gs_recall, gs_fscore = tune(df, 5, True, 'None', 0, False, features, 'gbm', [4], [200], [0.1])\n",
    "print(\"grid search precision:\", gs_precision)\n",
    "print(\"grid search recall:\", gs_recall)\n",
    "print(\"grid search f-score:\", gs_fscore)\n",
    "print(\"grid search hyper:\", gs_hyper)\n",
    "\n",
    "sqlContext.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### combo5: Amount ~ V4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 200, 0.1]\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.9315523987039842, 0.7726599682707562, 0.844699006735744]\n",
      "grid search precision: 0.9315523987039842\n",
      "grid search recall: 0.7726599682707562\n",
      "grid search f-score: 0.844699006735744\n",
      "grid search hyper: [4, 200, 0.1]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['Amount', 'V28', 'V25', 'V13', 'V3', 'V9', 'V6', 'V11', 'V15', 'V16', 'V2', 'V10', 'V19', 'V12', 'V27', 'V20', 'V24', 'V14', 'V8', 'V21', 'V5', 'V18', 'V7','V23', 'V22', 'V17','V4']\n",
    "gs_hyper, gs_precision, gs_recall, gs_fscore = tune(df, 5, True, 'None', 0, False, features, 'gbm', [4], [200], [0.1])\n",
    "print(\"grid search precision:\", gs_precision)\n",
    "print(\"grid search recall:\", gs_recall)\n",
    "print(\"grid search f-score:\", gs_fscore)\n",
    "print(\"grid search hyper:\", gs_hyper)\n",
    "\n",
    "sqlContext.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baed on t-test statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 200, 0.1]\n",
      "train after sampling: 145268\n",
      "fraud ratio: 0.001700305641985847\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145266\n",
      "fraud ratio: 0.0016934451282474908\n",
      "train after sampling: 145270\n",
      "fraud ratio: 0.0017002822330832244\n",
      "[0.9208561685543784, 0.7663141195134848, 0.836507244105671]\n",
      "grid search precision: 0.9208561685543784\n",
      "grid search recall: 0.7663141195134848\n",
      "grid search f-score: 0.836507244105671\n",
      "grid search hyper: [4, 200, 0.1]\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V14','V15','V16','V17','V18','V19','V20','V21','V24','V27','V28','Amount']\n",
    "gs_hyper, gs_precision, gs_recall, gs_fscore = tune(df, 5, True, 'None', 0, False, features, 'gbm', [4], [200], [0.1])\n",
    "print(\"grid search precision:\", gs_precision)\n",
    "print(\"grid search recall:\", gs_recall)\n",
    "print(\"grid search f-score:\", gs_fscore)\n",
    "print(\"grid search hyper:\", gs_hyper)\n",
    "\n",
    "sqlContext.clearCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### It is found that excluding any feature results in a performance drop, so all features are reserved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step6: Compare stratified cv with no smapling and undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4, 200, 0.1]\n",
      "train after sampling: 49399\n",
      "fraud ratio: 0.0050001012166238186\n",
      "train after sampling: 49200\n",
      "fraud ratio: 0.005\n",
      "train after sampling: 49200\n",
      "fraud ratio: 0.005\n",
      "train after sampling: 49200\n",
      "fraud ratio: 0.005\n",
      "train after sampling: 49399\n",
      "fraud ratio: 0.0050001012166238186\n",
      "[0.8613651637679555, 0.7922792173453199, 0.82537905440003]\n",
      "grids search precision: 0.8613651637679555\n",
      "grids search recall: 0.7922792173453199\n",
      "grids search f-score: 0.82537905440003\n",
      "[4, 200, 0.1]\n",
      "train after sampling: 24700\n",
      "fraud ratio: 0.01\n",
      "train after sampling: 24600\n",
      "fraud ratio: 0.01\n",
      "train after sampling: 24600\n",
      "fraud ratio: 0.01\n",
      "train after sampling: 24600\n",
      "fraud ratio: 0.01\n",
      "train after sampling: 24700\n",
      "fraud ratio: 0.01\n",
      "[0.8032088353973746, 0.8019566367001586, 0.8025822476251104]\n",
      "grids search precision: 0.8032088353973746\n",
      "grids search recall: 0.8019566367001586\n",
      "grids search f-score: 0.8025822476251104\n",
      "[4, 200, 0.1]\n",
      "train after sampling: 4939\n",
      "fraud ratio: 0.05001012350678275\n",
      "train after sampling: 4919\n",
      "fraud ratio: 0.05001016466761537\n",
      "train after sampling: 4919\n",
      "fraud ratio: 0.05001016466761537\n",
      "train after sampling: 4919\n",
      "fraud ratio: 0.05001016466761537\n",
      "train after sampling: 4939\n",
      "fraud ratio: 0.05001012350678275\n",
      "[0.36416602081040894, 0.8246430460074036, 0.5052232272375725]\n",
      "grids search precision: 0.36416602081040894\n",
      "grids search recall: 0.8246430460074036\n",
      "grids search f-score: 0.5052232272375725\n"
     ]
    }
   ],
   "source": [
    "df = sqlContext.read.csv(\"base_train.csv\", header = True)\n",
    "features = ['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19','V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount']\n",
    "\n",
    "for i in [0.005,0.01,0.05]:\n",
    "    cv_hyper, cv_precision, cv_recall, cv_fscore = tune(df, 5, True, 'under', i, False, features, 'gbm', [4],[200],[0.1])\n",
    "    print(\"grids search precision:\", cv_precision)\n",
    "    print(\"grids search recall:\", cv_recall)\n",
    "    print(\"grids search f-score:\", cv_fscore)\n",
    "\n",
    "sqlContext.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train after sampling: 61599\n",
      "fraud ratio: 0.005000081170148866\n",
      "Precision is  0.8571428571428571\n",
      "Recall is  0.8571428571428571\n",
      "F1 score is  0.8571428571428571\n",
      "Test Area Under ROC: 0.9836296360080017\n"
     ]
    }
   ],
   "source": [
    "train_df= sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('base_train.csv')\n",
    "test_df= sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('base_test.csv')\n",
    "\n",
    "train_df = sample(train_df, \"under\", 0.005)\n",
    "vectorAssembler = VectorAssembler(inputCols = ['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19','V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount'], outputCol = 'features')\n",
    "train_df_v = vectorAssembler.transform(train_df)\n",
    "test_df_v = vectorAssembler.transform(test_df)\n",
    "gbt = GBTClassifier(featuresCol = 'features',labelCol = 'Class', maxDepth = 4, maxIter = 200, stepSize = 0.1)\n",
    "\n",
    "gbt_model = gbt.fit(train_df_v)\n",
    "gbt_prediction = gbt_model.transform(test_df_v)\n",
    "#bt_prediction.select('features','Class','prediction').show()\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Class\", metricName=\"areaUnderROC\")\n",
    "area = evaluator.evaluate(gbt_prediction)\n",
    "pred = gbt_prediction\n",
    "precision = pred.filter(pred.Class == pred.prediction).filter(pred.Class == 1.0).count() / pred.filter(pred.prediction == 1.0).count()\n",
    "recall = pred.filter(pred.Class == pred.prediction).filter(pred.Class == 1.0).count() / pred.filter(pred.Class == 1.0).count()\n",
    "f1 = 2 * precision * recall /(precision + recall)\n",
    "print(\"Precision is \", precision)\n",
    "print(\"Recall is \", recall)\n",
    "print(\"F1 score is \", f1)\n",
    "print(\"Test Area Under ROC: \" + str(area))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No performance improvement by undersamping, so just keep using entire dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step7: hold-out test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision is  0.9272727272727272\n",
      "Recall is  0.6891891891891891\n",
      "F1 score is  0.7906976744186047\n",
      "Test Area Under ROC: 0.9881642300120628\n"
     ]
    }
   ],
   "source": [
    "train_df= sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('base_train.csv')\n",
    "oot_df= sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('oot.csv')\n",
    "vectorAssembler = VectorAssembler(inputCols = ['V1','V2','V3','V4','V5','V6','V7','V8','V9','V10','V11','V12','V13','V14','V15','V16','V17','V18','V19','V20','V21','V22','V23','V24','V25','V26','V27','V28','Amount'], outputCol = 'features')\n",
    "train_df_v = vectorAssembler.transform(train_df)\n",
    "oot_df_v = vectorAssembler.transform(oot_df)\n",
    "gbt = GBTClassifier(featuresCol = 'features',labelCol = 'Class', maxDepth = 4, maxIter = 200, stepSize = 0.1)\n",
    "\n",
    "gbt_model = gbt.fit(train_df_v)\n",
    "gbt_prediction = gbt_model.transform(oot_df_v)\n",
    "\n",
    "evaluator = BinaryClassificationEvaluator(labelCol=\"Class\", metricName=\"areaUnderROC\")\n",
    "area = evaluator.evaluate(gbt_prediction)\n",
    "pred = gbt_prediction\n",
    "precision = pred.filter(pred.Class == pred.prediction).filter(pred.Class == 1.0).count() / pred.filter(pred.prediction == 1.0).count()\n",
    "recall = pred.filter(pred.Class == pred.prediction).filter(pred.Class == 1.0).count() / pred.filter(pred.Class == 1.0).count()\n",
    "f1 = 2 * precision * recall /(precision + recall)\n",
    "print(\"Precision is \", precision)\n",
    "print(\"Recall is \", recall)\n",
    "print(\"F1 score is \", f1)\n",
    "print(\"Test Area Under ROC: \" + str(area))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
